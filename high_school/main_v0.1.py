# FastAPI ê¸°ë³¸ í˜•ì„ ì‘ì„±í•´ ì£¼ì„¸ìš”. ê°€ì¥ ê¸°ë³¸ì´ ë˜ëŠ” app ì™€ '/' url ì•  ëŒ€í•œ ì‚¬í•­ë§Œ ì ìš©í•¨
from fastapi import FastAPI, Request, Form
from fastapi.responses import HTMLResponse, RedirectResponse
from fastapi.templating import Jinja2Templates
from fastapi.staticfiles import StaticFiles
from typing import List, Optional
# openai ì˜ OpenAI APIë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ import
from openai import OpenAI
# python-dotenvë¥¼ ì‚¬ìš©í•˜ì—¬ í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
from dotenv import load_dotenv
import os
from datetime import datetime


# OpenAI API í‚¤ ì„¤ì •
load_dotenv()
_key = os.getenv("OPENAI_API_KEY")
#openai.api_key = _key
client = OpenAI(api_key=_key) # Or it will pick from environment variable

app = FastAPI()
templates_dir = os.path.join(os.path.dirname(__file__), "templates")
templates = Jinja2Templates(directory=templates_dir)
# ì •ì  íŒŒì¼(static) ê²½ë¡œ ë“±ë¡
import os
static_dir = os.path.join(os.path.dirname(__file__), "static")
app.mount("/static", StaticFiles(directory=static_dir), name="static")

@app.get("/")
async def index():
    return RedirectResponse(url="/career/flow")

# ì§„ë¡œ íƒìƒ‰ì„ ìœ„í•œ career ëª©ë¡ì„ ì €ì¥í•˜ê¸° ìœ„í•œ ë°ì´í„° êµ¬ì¡°
# ì§„ë¡œ íƒìƒ‰ 1ë‹¨ê³„ ì›í•˜ëŠ” ì§ì—…ì„ íƒ

# íŒŒì´ì¬ ë¦¬ìŠ¤íŠ¸ í˜•ì‹ì˜ ìë£Œêµ¬ì¡° ë¥¼ ì‚¬ìš©í•˜ì—¬ career ëª©ë¡ì„ ì €ì¥
# ì§„ë¡œ ê°€ì¹˜ íƒìƒ‰ 2ë‹¨ê³„ í”„ë¡¬í”„íŠ¸ì™€ ì„ íƒì§€ë¥¼ ë¦¬ìŠ¤íŠ¸ êµ¬ì¡°ë¡œ ì •ì˜
career_value_prompt = "2ë‹¨ê³„ ì™œ ì´ {career} ì„ í¬ë§í•˜ë‚˜ìš”? (ë³µìˆ˜ ì„ íƒ ê°€ëŠ¥)"
career_value_choices = [
    {"id": 1, "label": "ê²½ì œì  ê°€ì¹˜", "description": "ë†’ì€ ìˆ˜ì…, ì•ˆì •ì ì¸ ì§ì—…"},
    {"id": 2, "label": "ì‚¬íšŒì  ê°€ì¹˜", "description": "ì‚¬íšŒì— ê¸ì •ì ì¸ ì˜í–¥, ë´‰ì‚¬"},
    {"id": 3, "label": "ê³µë™ì²´ì  ê°€ì¹˜", "description": "ì‚¬ëŒë“¤ê³¼ í˜‘ë ¥, ì†Œí†µ"},
    {"id": 4, "label": "ëŠ¥ë ¥ ë°œíœ˜", "description": "ë‚˜ì˜ ì¬ëŠ¥ê³¼ ì—­ëŸ‰ì„ ìµœëŒ€í•œ ë°œíœ˜"},
    {"id": 5, "label": "ììœ¨Â·ì°½ì˜ì„±", "description": "ë…ë¦½ì ìœ¼ë¡œ ì¼í•˜ê³  ìƒˆë¡œìš´ ì•„ì´ë””ì–´ ì°½ì¶œ"},
    {"id": 6, "label": "ë¯¸ë˜ ë¹„ì „", "description": "ì„±ì¥ ê°€ëŠ¥ì„±, í˜ì‹ ì ì¸ ë¶„ì•¼"},
]

# ì§„ë¡œ ê°€ì¹˜ íƒìƒ‰ 3ë‹¨ê³„ í”„ë¡¬í”„íŠ¸ ì •ì˜ (ì„ íƒì§€ëŠ” ì˜ˆì‹œë¡œë§Œ ì£¼ì„ì— ëª…ì‹œ, ì‹¤ì œë¡œëŠ” ë§¤ë²ˆ ìƒì„±)
career_issue_prompt = (
    """
    3ë‹¨ê³„.
    ë‹¹ì‹ ì´ ì„ íƒí•œ '{career}' ì§ì—…ê³¼ ê´€ë ¨ëœ ìµœì‹  ì´ìŠˆ ë˜ëŠ” í•´ê²° ê³¼ì œ ì¤‘ ê°€ì¥ ê´€ì‹¬ ìˆëŠ” ê²ƒì€ 5ê°€ì§€ ì œì‹œí•´ ì£¼ì„¸ìš”.
    # ì˜ˆì‹œ: ê¸°í›„ ìœ„ê¸°ì— ëŒ€ì‘í•˜ëŠ” ì§€ì† ê°€ëŠ¥í•œ ê±´ì¶• ê¸°ìˆ  ë¶€ì¡±, ê³ ë ¹í™” ì‚¬íšŒì˜ ëŒë´„ ì‹œìŠ¤í…œ ê°œì„ , ì¸ê³µì§€ëŠ¥ ìœ¤ë¦¬ ë¬¸ì œ í•´ê²°,
    # ë””ì§€í„¸ ê²©ì°¨ í•´ì†Œ ë°©ì•ˆ, ë¬¸í™” ì½˜í…ì¸ ì˜ ê¸€ë¡œë²Œ ê²½ìŸë ¥ ê°•í™”
    """
)
# ì‹¤ì œ ì„ íƒì§€ëŠ” OpenAI APIë¥¼ í†µí•´ careerì— ë”°ë¼ ë™ì ìœ¼ë¡œ ìƒì„±

# ì§„ë¡œ ê°€ì¹˜ íƒìƒ‰ 4ë‹¨ê³„ í”„ë¡¬í”„íŠ¸ ì •ì˜ (ì„ íƒì§€ëŠ” ì˜ˆì‹œë¡œë§Œ ì£¼ì„ì— ëª…ì‹œ, ì‹¤ì œë¡œëŠ” ë§¤ë²ˆ ìƒì„±)
career_topic_prompt = (
    """
    4ë‹¨ê³„.
    ì•ì„œ ì„ íƒí•œ '{career}' ì§ì—…ê³¼ ê´€ë ¨ëœ ì´ìŠˆ ì¤‘ '{issue}' ì´ìŠˆì— ëŒ€í•´ 
    ì„ íƒëœ ë¬¸ì œì— ëŒ€í•´ êµ¬ì²´ì ìœ¼ë¡œ íƒêµ¬ ê°€ëŠ¥í•œ ì£¼ì œ 5ê°€ì§€ ì œì‹œí•´ì£¼ì„¸ìš”.
    # ê¸°ìˆ /ì •ì±…/ì‹¬ë¦¬/êµìœ¡/ë°ì´í„° ë¶„ì„ ë“± ë‹¤ì–‘í•œ ë°©ë²•ë¡  ì œì‹œ
    # ì¤‘ë³µ ì—†ì´ ìƒˆë¡œìš´ ì‹œì„  ê°•ì¡°
    """
)

# ì§„ë¡œ ê°€ì¹˜ íƒìƒ‰ 5ë‹¨ê³„ í”„ë¡¬í”„íŠ¸ ì •ì˜ (ì„ íƒì§€ëŠ” ì˜ˆì‹œë¡œë§Œ ì£¼ì„ì— ëª…ì‹œ, ì‹¤ì œë¡œëŠ” ë§¤ë²ˆ ìƒì„±)
career_goal_prompt = (
    """
    5ë‹¨ê³„.
    ì§€ê¸ˆê¹Œì§€ ì„ íƒí•œ ì§ì—…: '{career}', ì´ìœ : {reasons}, ì´ìŠˆ: '{issue}', íƒêµ¬ ì£¼ì œ: '{topic}'ë¥¼ ë°”íƒ•ìœ¼ë¡œ
    ì‚¬ìš©ìì—ê²Œ ì§„ë¡œ ëª©í‘œë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ ì œì‹œí•´ ì£¼ì„¸ìš”.
    {reasons} ì—ì„œ ì„ íƒí•œ ê°’ì„ ì°¸ê³ í•´ì„œ ê°€ì¹˜ê´€ì´ ì˜ ë“œëŸ¬ë‚˜ë„ë¡ êµ¬ì²´ì ìœ¼ë¡œ í‘œí˜„í•´ ì£¼ì„¸ìš”.
    # ì˜ˆì‹œ: 'ê¸°í›„ ìœ„ê¸° ëŒ€ì‘ì„ ìœ„í•œ ì¹œí™˜ê²½ ê±´ì¶• ì‹œìŠ¤í…œì„ ì„¤ê³„í•˜ì—¬ ì§€ì†ê°€ëŠ¥í•œ ë¯¸ë˜ ì£¼ê±° í˜•íƒœë¥¼ ì‹¤í˜„í•˜ëŠ” ê²ƒ
    """
)

# ì§„ë¡œ ê°€ì¹˜ íƒìƒ‰ 6ë‹¨ê³„ í”„ë¡¬í”„íŠ¸ ì •ì˜ (ì„ íƒì§€ëŠ” ì˜ˆì‹œë¡œë§Œ ì£¼ì„ì— ëª…ì‹œ, ì‹¤ì œë¡œëŠ” ë§¤ë²ˆ ìƒì„±)
career_midgoal_prompt = (
    """
    6ë‹¨ê³„.
    ì§€ê¸ˆê¹Œì§€ ì„ íƒí•œ ì§ì—…: '{career}', ì´ìœ : {reasons}, ì´ìŠˆ: '{issue}', íƒêµ¬ ì£¼ì œ: '{topic}', ìµœì¢… ëª©í‘œ: '{goal}'ì„(ë¥¼) ë°”íƒ•ìœ¼ë¡œ
    ìµœì¢… ëª©í‘œë¥¼ ì‹¤í˜„í•˜ê¸° ìœ„í•´ ê³ ë“±í•™ìƒ ìˆ˜ì¤€ì—ì„œ ê¸¸ëŸ¬ì•¼ í•  í•µì‹¬ ì—­ëŸ‰ ê¸°ë°˜ ì¤‘ê°„ ëª©í‘œ 3ê°œë¥¼ ì œì‹œí•´ ì£¼ì„¸ìš”
    
    [1] í•™ì—…ì—­ëŸ‰ì„ í¬í•¨í•˜ëŠ” ë‚´ìš©ìœ¼ë¡œ ì œì‹œ
    [2] ì§„ë¡œì—­ëŸ‰ë¥¼ í¬í•¨í•˜ëŠ” ë‚´ìš©ìœ¼ë¡œ ì œì‹œ
    [3] ê³µë™ì²´ì—­ëŸ‰ë¥¼ í¬í•¨í•˜ëŠ” ë‚´ìš©ìœ¼ë¡œ ì œì‹œ
    # ì˜ˆì‹œ: ì¹œí™˜ê²½ ê¸°ìˆ  ì—­ëŸ‰ ê°•í™” / ì„¤ê³„ ëŠ¥ë ¥ í–¥ìƒ / ê³µë™ì²´ì  ì‹¤ì²œì˜ì‹ í•¨ì–‘
    """
)

# ì§„ë¡œ ê°€ì¹˜ íƒìƒ‰ 7ë‹¨ê³„ í”„ë¡¬í”„íŠ¸ ì •ì˜ (ìµœì¢… í†µí•© ì •ë¦¬)
career_final_summary_prompt = (
    """
    7ë‹¨ê³„.
    ì§€ê¸ˆê¹Œì§€ ì„ íƒí•œ ì§ì—…: '{career}', ì´ìœ : {reasons}, ì´ìŠˆ: '{issue}', íƒêµ¬ ì£¼ì œ: '{topic}',
    ìµœì¢… ëª©í‘œ: '{goal}', ì¤‘ê°„ ëª©í‘œ: {midgoals}, ì„(ë¥¼) ë°”íƒ•ìœ¼ë¡œ ì•„ë˜ í˜•ì‹ìœ¼ë¡œ ëª¨ë“  ë‚´ìš©ì„ í†µí•©í•˜ì—¬ ì •ë¦¬í•´ ì£¼ì„¸ìš”.
    ìµœì¢…ëª©í‘œ, ì¤‘ê°„ëª©í‘œ, ì‹¤ì²œí™œë™ì—ë§Œ ì´ëª¨ì§€ë¥¼ ì‚¬ìš©í•´ì„œ ì‹œê°ì ìœ¼ë¡œ ë§¤ë ¥ì ì´ê³  ì½ê¸° ì‰½ê²Œ ë§Œë“¤ì–´ì£¼ì„¸ìš”.
    ì œí•œì¡°ê±´ì€ ê²°ê³¼ì— í‘œì‹œí•˜ì§€ ë§ê³  ë‚´ë¶€ì ìœ¼ë¡œë§Œ ì°¸ê³ í•˜ì„¸ìš”:
    ì•„ë˜ëŠ” ê±´ì¶•ê°€ë¥¼ í¬ë§í•˜ëŠ” ê³ ë“±í•™ìƒì˜ ì§„ë¡œ íƒìƒ‰ ê²°ê³¼ ì˜ˆì‹œì…ë‹ˆë‹¤.
    
    # ì˜ˆì‹œ:
        ğŸ¯ [ìµœì¢… ëª©í‘œ(ê¿ˆ)] ê¸°í›„ ìœ„ê¸° ëŒ€ì‘ì„ ìœ„í•œ ì¹œí™˜ê²½ ê±´ì¶• ì‹œìŠ¤í…œ ì„¤ê³„í•˜ì—¬ ì§€ì†ê°€ëŠ¥í•œ ë¯¸ë˜ ì£¼ê±° í˜•íƒœë¥¼ ì‹¤í˜„í•˜ëŠ” ê±´ì¶•ê°€

        ğŸ“š [ì¤‘ê°„ëª©í‘œ1] ì¹œí™˜ê²½ ê±´ì¶• ê¸°ìˆ  ì—­ëŸ‰
        ğŸ”¬ ì‹¤ì²œí™œë™1:
                    íƒêµ¬ë³´ê³ ì„œ: "ì œë¡œì—ë„ˆì§€ ê±´ì¶• ê¸°ìˆ ì˜ ì‹¤ì œ ì ìš© ì‚¬ë¡€ ë¶„ì„" ë“±
                    ê³ 1 êµê³¼ í™œë™: ê³µí†µ ê³¼í•™ - 'ì—ë„ˆì§€ ì „í™˜' ë‹¨ì› [ì‹¬í™”]
                    ê³ 1 ë¹„êµê³¼: ì—ë„ˆì§€ ì°½ì˜ ì„¤ê³„ ìº í”„ ì°¸ê°€ - [ë¬¸ì œ í•´ê²°ë ¥ ì„±ì¥ê³¼ ê´€ë ¨]
        ğŸ”¬ ì‹¤ì²œí™œë™2:
                    íƒêµ¬ë³´ê³ ì„œ:
                    ê³ 2 êµê³¼ í™œë™: ìƒëª…
                    ê³ 2 ë¹„êµê³¼:
        ğŸ”¬ ì‹¤ì²œí™œë™3:
                    íƒêµ¬ë³´ê³ ì„œ:  
                    ê³ 3 êµê³¼ í™œë™: ìœ ì „ìì™€~~
                    ê³ 3 ë¹„êµê³¼:  
        
        ğŸ¨ [ì¤‘ê°„ëª©í‘œ2] ì„¤ê³„ ëŠ¥ë ¥ í–¥ìƒ
        ğŸ”¬ ì‹¤ì²œí™œë™1:
                    íƒêµ¬ë³´ê³ ì„œ: "ê±´ì¶• ì„¤ê³„ì˜ ê¸°ì´ˆì™€ ì‹¤ì œ" ë“±
                    ê³ 1 êµê³¼ í™œë™: ê³µí†µ ê¸°ìˆ  - 'ê¸°ì´ˆ ì„¤ê³„ ì›ë¦¬'
                    ê³ 1 ë¹„êµê³¼: ê±´ì¶• ì„¤ê³„ ì›Œí¬ìˆ ì°¸ê°€ - [ì°½ì˜ì  ë¬¸ì œ í•´ê²°ë ¥ ì„±ì¥ê³¼ ê´€ë ¨]
        ğŸ”¬ ì‹¤ì²œí™œë™2:
                    íƒêµ¬ë³´ê³ ì„œ: "ê±´ì¶• ì„¤ê³„ì˜ ê¸°ì´ˆì™€ ì‹¤ì œ" ë“±
                    ê³ 2 êµê³¼ í™œë™: ê³µí†µ ê¸°ìˆ  - 'ê³ ê¸‰ ì„¤ê³„ ê¸°ë²•'
                    ê³ 2 ë¹„êµê³¼: ê±´ì¶• ì„¤ê³„ ê²½ì§„ëŒ€íšŒ ì°¸ê°€ - [ì°½ì˜ì  ë¬¸ì œ í•´ê²°ë ¥ ì„±ì¥ê³¼ ê´€ë ¨]
        ğŸ”¬ ì‹¤ì²œí™œë™3:
                    íƒêµ¬ë³´ê³ ì„œ: "ê±´ì¶• ì„¤ê³„ì˜ ê¸°ì´ˆì™€ ì‹¤ì œ" ë“±
                    ê³ 3 êµê³¼ í™œë™: ê³µí†µ ê¸°ìˆ  - 'ê±´ì¶• ì„¤ê³„ í”„ë¡œì íŠ¸'
                    ê³ 3 ë¹„êµê³¼: ê±´ì¶• ì„¤ê³„ í”„ë¡œì íŠ¸ ë°œí‘œíšŒ ì°¸ê°€ - [ì°½ì˜ì  ë¬¸ì œ í•´ê²°ë ¥ ì„±ì¥ê³¼ ê´€ë ¨]
        
        ğŸ¤ [ì¤‘ê°„ëª©í‘œ3] ê³µë™ì²´ì  ì‹¤ì²œì˜ì‹ í•¨ì–‘
        ğŸ”¬ ì‹¤ì²œí™œë™1:
        
        ì œí•œ ì¡°ê±´ (ê²°ê³¼ì— í‘œì‹œí•˜ì§€ ë§ê³  ë‚´ë¶€ì ìœ¼ë¡œë§Œ ì°¸ê³ ):
        1. í•™ë…„ë³„ êµê³¼ í™œë™ì˜ ê²½ìš° '2022 êµìœ¡ê°œí¸ì¤‘ ê³ ë“±í•™êµ êµìœ¡ê³¼ì •' ë°˜ì˜í•˜ì—¬ í™œë™ ì œì‹œ
        2. í•™êµì™¸ì— ëŒ€íšŒë‚˜ ê³µëª¨ì „ì€ ì–¸ê¸‰í•˜ì§€ ì•Šê¸°. í•™êµì—ì„œ ì´ë£¨ì–´ì§ˆ ìˆ˜ ìˆëŠ” í™œë™ìœ¼ë¡œë§Œ ì‹¤ì²œí™œë™ ì œì‹œí•˜ê¸°
        3. ìì†Œì„œ ë“±ì€ ì–¸ê¸‰í•˜ì§€ ì•Šê¸°
        4. ê³ ë“±í•™ìƒ ìˆ˜ì¤€ì—ì„œ ì´í•´ í•  ìˆ˜ ìˆëŠ” íƒêµ¬í™œë™ ì£¼ì œ ì œì‹œ
            "ê° í•­ëª©ì€ ì‹¤ì œ ì…ë ¥ê°’ì— ë§ê²Œ êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”."
    """
)



@app.get("/career/flow", response_class=HTMLResponse)
async def career_flow_get(request: Request):
    now = datetime.now().timestamp()
    return templates.TemplateResponse("career_flow_allinone.html", {"request": request, "step": 1, "start_time": now, "step_start_time": now})

@app.post("/career/flow", response_class=HTMLResponse)
async def career_flow_post(
    request: Request,
    step: int = Form(1),
    career: Optional[str] = Form(None),
    reasons: Optional[List[str]] = Form(None),
    issue: Optional[str] = Form(None),
    topic: Optional[str] = Form(None),
    goal: Optional[str] = Form(None),
    midgoals: Optional[List[str]] = Form(None),
    midgoal_details: Optional[str] = Form(None),
    practices: Optional[str] = Form(None),
    start_time: Optional[float] = Form(None),
    step_start_time: Optional[float] = Form(None),
):
    now = datetime.now().timestamp()
    context = {"request": request, "step": step}
    # start_time ê´€ë¦¬
    if not start_time:
        start_time = now
    context["start_time"] = start_time
    # step_start_time ê´€ë¦¬ (ë‹¨ê³„ë³„ ì†Œìš” ì‹œê°„ ì‚­ì œ, current_step_timeë„ ì‚­ì œ)
    if not step_start_time:
        step_start_time = now
    context["step_start_time"] = step_start_time
    chatbot_message = None
    # 1ë‹¨ê³„: ì§ì—… ì…ë ¥
    if step == 1:
        if not career:
            context.update({"error": "ì§ì—…ì„ ì…ë ¥í•˜ì„¸ìš”."})
            return templates.TemplateResponse("career_flow_allinone.html", context)
        choices = career_value_choices
        chatbot_message = f"'{career}'(ì„)ë¥¼ ì„ íƒí•˜ì…¨êµ°ìš”. ì´ ì§ì—…ì„ ì„ íƒí•œ ì´ìœ ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”!"
        context.update({"step": 2, "career": career, "choices": choices, "chatbot_message": chatbot_message})
        return templates.TemplateResponse("career_flow_allinone.html", context)
    # 2ë‹¨ê³„: ì´ìœ  ë³µìˆ˜ ì„ íƒ
    elif step == 2:
        if not (career and reasons):
            context.update({"step": 2, "career": career, "choices": career_value_choices, "error": "ì´ìœ ë¥¼ í•œ ê°€ì§€ ì´ìƒ ì„ íƒí•˜ì„¸ìš”."})
            return templates.TemplateResponse("career_flow_allinone.html", context)
        chatbot_message = f"{', '.join(reasons)}(ì„)ë¥¼ ì„ íƒí•˜ì…¨êµ°ìš”. ì´ì œ {career}ì™€ ê´€ë ¨ëœ ìµœì‹  ì´ìŠˆë¥¼ ê³¨ë¼ë³¼ê¹Œìš”?"
        # 3ë‹¨ê³„ë¡œ ì´ë™ (OpenAI APIë¡œ ì´ìŠˆ ìƒì„±)
        issues = call_gpt_list(
            prompt=career_issue_prompt.format(career=career),
            system_message="ë„ˆëŠ” ì§„ë¡œ íƒìƒ‰ì„ ë•ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ì•¼. ì‚¬ìš©ìê°€ ì„ íƒí•œ ì§ì—…ê³¼ ê´€ë ¨ëœ ìµœì‹  ì´ìŠˆë‚˜ í•´ê²° ê³¼ì œ 5ê°€ì§€ë¥¼ í•œêµ­ì–´ë¡œ ê°„ê²°í•˜ê²Œ ì œì‹œí•´ì¤˜.",
            max_tokens=1000,
            fallback=["ì´ìŠˆë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."],
            strip_chars='-â€¢ '
        )
        context.update({"step": 3, "career": career, "reasons": reasons, "issues": issues, "chatbot_message": chatbot_message})
        return templates.TemplateResponse("career_flow_allinone.html", context)
    # 3ë‹¨ê³„: ì´ìŠˆ ì„ íƒ
    elif step == 3:
        form = await request.form()
        regenerate = form.get("regenerate")
        # ë‹¤ì¤‘ ì„ íƒ ì§€ì›: issuesëŠ” ë¦¬ìŠ¤íŠ¸
        issues_selected = [str(x) for x in form.getlist("issues")]
        # 'ë‹¤ì‹œ ìƒì„±' ë²„íŠ¼ ì²˜ë¦¬
        if regenerate == "yes":
            issues = call_gpt_list(
                prompt=career_issue_prompt.format(career=career),
                system_message="ë„ˆëŠ” ì§„ë¡œ íƒìƒ‰ì„ ë•ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ì•¼. ì‚¬ìš©ìê°€ ì„ íƒí•œ ì§ì—…ê³¼ ê´€ë ¨ëœ ìµœì‹  ì´ìŠˆë‚˜ í•´ê²° ê³¼ì œ 5ê°€ì§€ë¥¼ í•œêµ­ì–´ë¡œ ê°„ê²°í•˜ê²Œ ì œì‹œí•´ì¤˜.",
                max_tokens=1000,
                fallback=["ì´ìŠˆë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."],
                strip_chars='-â€¢ '
            )
            chatbot_message = f"ì´ìŠˆë¥¼ ìƒˆë¡œ ì œì•ˆí•©ë‹ˆë‹¤. ì›í•˜ëŠ” ì´ìŠˆë¥¼ ëª¨ë‘ ì„ íƒí•˜ì„¸ìš”."
            context.update({"step": 3, "career": career, "reasons": reasons, "issues": issues, "chatbot_message": chatbot_message, "issues_selected": []})
            return templates.TemplateResponse("career_flow_allinone.html", context)
        if not (career and reasons and issues_selected):
            context.update({"step": 3, "career": career, "reasons": reasons, "issues": context.get("issues", []), "error": "ì´ìŠˆë¥¼ í•œ ê°€ì§€ ì´ìƒ ì„ íƒí•˜ì„¸ìš”.", "issues_selected": issues_selected})
            return templates.TemplateResponse("career_flow_allinone.html", context)
        chatbot_message = f"{', '.join(issues_selected)}(ì„)ë¥¼ ì„ íƒí•˜ì…¨êµ°ìš”. ì´ ì´ìŠˆë“¤ì— ëŒ€í•´ íƒêµ¬í•˜ê³  ì‹¶ì€ ì£¼ì œë¥¼ ê³¨ë¼ì£¼ì„¸ìš”!"
        # 4ë‹¨ê³„ë¡œ ì´ë™ (OpenAI APIë¡œ íƒêµ¬ ì£¼ì œ ìƒì„±, ì²« ë²ˆì§¸ ì´ìŠˆë§Œ ì‚¬ìš©)
        topics = call_gpt_list(
            prompt=career_topic_prompt.format(career=career, issue=issues_selected[0]),
            system_message="ë„ˆëŠ” ì§„ë¡œ íƒìƒ‰ì„ ë•ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ì•¼. ì‚¬ìš©ìê°€ ì„ íƒí•œ ì´ìŠˆì— ëŒ€í•´ êµ¬ì²´ì ìœ¼ë¡œ íƒêµ¬ ê°€ëŠ¥í•œ ì£¼ì œ 3ê°€ì§€ë¥¼ í•œêµ­ì–´ë¡œ ê°„ê²°í•˜ê²Œ ì œì‹œí•´ì¤˜.",
            max_tokens=1000,
            fallback=["ì£¼ì œë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."],
            strip_chars='-â€¢[]1234567890. '
        )
        context.update({"step": 4, "career": career, "reasons": reasons, "issues_selected": issues_selected, "topics": topics, "chatbot_message": chatbot_message})
        return templates.TemplateResponse("career_flow_allinone.html", context)
    # 4ë‹¨ê³„: íƒêµ¬ ì£¼ì œ ì„ íƒ
    elif step == 4:
        form = await request.form()
        regenerate = form.get("regenerate")
        topic = form.get("topic") # type: ignore
        # issues_selectedë¥¼ hidden inputì—ì„œ ë°›ì•„ì˜´
        issues_selected = form.getlist("issues_selected")
        
        # 'ë‹¤ì‹œ ìƒì„±' ë²„íŠ¼ ì²˜ë¦¬
        if regenerate == "yes":
            topics = call_gpt_list(
                prompt=career_topic_prompt.format(career=career, issue=issues_selected[0]),
                system_message="ë„ˆëŠ” ì§„ë¡œ íƒìƒ‰ì„ ë•ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ì•¼. ì‚¬ìš©ìê°€ ì„ íƒí•œ ì´ìŠˆì— ëŒ€í•´ êµ¬ì²´ì ìœ¼ë¡œ íƒêµ¬ ê°€ëŠ¥í•œ ì£¼ì œ 3ê°€ì§€ë¥¼ í•œêµ­ì–´ë¡œ ê°„ê²°í•˜ê²Œ ì œì‹œí•´ì¤˜.",
                max_tokens=1000,
                fallback=["ì£¼ì œë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."],
                strip_chars='-â€¢[]1234567890. '
            )
            chatbot_message = f"ì£¼ì œë¥¼ ìƒˆë¡œ ì œì•ˆí•©ë‹ˆë‹¤. ì›í•˜ëŠ” ì£¼ì œë¥¼ ì„ íƒí•˜ì„¸ìš”."
            context.update({"step": 4, "career": career, "reasons": reasons, "issues_selected": issues_selected, "topics": topics, "chatbot_message": chatbot_message})
            return templates.TemplateResponse("career_flow_allinone.html", context)
        
        # ì£¼ì œ ì„ íƒ ê²€ì¦ (ì¬ìƒì„±ì´ ì•„ë‹Œ ê²½ìš°ì—ë§Œ)
        if not (career and reasons and issues_selected):
            context.update({"step": 4, "career": career, "reasons": reasons, "issues_selected": issues_selected, "topics": ["ì£¼ì œë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."], "error": "ì´ì „ ë‹¨ê³„ ì •ë³´ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤."})
            return templates.TemplateResponse("career_flow_allinone.html", context)
        
        if not topic:
            # ì£¼ì œê°€ ì„ íƒë˜ì§€ ì•Šì€ ê²½ìš°, ê¸°ë³¸ topics ìƒì„±
            topics = call_gpt_list(
                prompt=career_topic_prompt.format(career=career, issue=issues_selected[0]),
                system_message="ë„ˆëŠ” ì§„ë¡œ íƒìƒ‰ì„ ë•ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ì•¼. ì‚¬ìš©ìê°€ ì„ íƒí•œ ì´ìŠˆì— ëŒ€í•´ êµ¬ì²´ì ìœ¼ë¡œ íƒêµ¬ ê°€ëŠ¥í•œ ì£¼ì œ 3ê°€ì§€ë¥¼ í•œêµ­ì–´ë¡œ ê°„ê²°í•˜ê²Œ ì œì‹œí•´ì¤˜.",
                max_tokens=1000,
                fallback=["ì£¼ì œë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."],
                strip_chars='-â€¢[]1234567890. '
            )
            context.update({"step": 4, "career": career, "reasons": reasons, "issues_selected": issues_selected, "topics": topics, "error": "ì£¼ì œë¥¼ ì„ íƒí•˜ì„¸ìš”."})
            return templates.TemplateResponse("career_flow_allinone.html", context)
        # 5ë‹¨ê³„: GPTê°€ ì œì‹œí•˜ëŠ” ì§„ë¡œ ëª©í‘œ
        suggested_goal = call_gpt_list(
            prompt=career_goal_prompt.format(career=career, reasons=reasons, issue=issues_selected[0], topic=topic),
            system_message="ë„ˆëŠ” ì§„ë¡œ íƒìƒ‰ì„ ë•ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ì•¼. ì‚¬ìš©ìì˜ ì„ íƒì„ ë°”íƒ•ìœ¼ë¡œ ì ì ˆí•œ ì§„ë¡œ ëª©í‘œë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ ì œì‹œí•´ì¤˜.",
            max_tokens=100,
            fallback=["ì§„ë¡œ ëª©í‘œë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."],
            strip_chars=''  # í•œ ë¬¸ì¥ë§Œ ë°˜í™˜
        )[0]
        chatbot_message = f"ì•„ë˜ì™€ ê°™ì€ ì§„ë¡œ ëª©í‘œë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ë§ˆìŒì— ë“¤ì§€ ì•Šìœ¼ë©´ 'ë‹¤ì‹œ ìƒì„±'ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”."
        context.update({"step": 5, "career": career, "reasons": reasons, "issues_selected": issues_selected, "topic": topic, "suggested_goal": suggested_goal, "chatbot_message": chatbot_message})
        return templates.TemplateResponse("career_flow_allinone.html", context)
    # 5ë‹¨ê³„: ì§„ë¡œ ëª©í‘œ í™•ì¸ ë° ì¬ìƒì„±
    elif step == 5:
        form = await request.form()
        suggested_goal = form.get("suggested_goal")
        regenerate = form.get("regenerate")
        issues_selected = form.getlist("issues_selected")
        if regenerate == "yes":
            # ëª©í‘œ ì¬ìƒì„±
            suggested_goal = call_gpt_list(
                prompt=career_goal_prompt.format(career=career, reasons=reasons, issue=issues_selected[0], topic=topic),
                system_message="ë„ˆëŠ” ì§„ë¡œ íƒìƒ‰ì„ ë•ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ì•¼. ì‚¬ìš©ìì˜ ì„ íƒì„ ë°”íƒ•ìœ¼ë¡œ ì ì ˆí•œ ì§„ë¡œ ëª©í‘œë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ ì œì‹œí•´ì¤˜.",
                max_tokens=100,
                fallback=["ì§„ë¡œ ëª©í‘œë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."],
                strip_chars=''
            )[0]
            chatbot_message = "ì•„ë˜ì™€ ê°™ì´ ìƒˆë¡­ê²Œ ì§„ë¡œ ëª©í‘œë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ë§ˆìŒì— ë“¤ì§€ ì•Šìœ¼ë©´ ë‹¤ì‹œ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            context.update({"step": 5, "career": career, "reasons": reasons, "issues_selected": issues_selected, "topic": topic, "suggested_goal": suggested_goal, "chatbot_message": chatbot_message})
            return templates.TemplateResponse("career_flow_allinone.html", context)
        # ì‚¬ìš©ìê°€ ëª©í‘œë¥¼ ìˆ˜ë½
        goal = str(suggested_goal) if suggested_goal is not None else None
        chatbot_message = f"'{goal}'(ì„)ë¥¼ ëª©í‘œë¡œ í•˜ì…¨êµ°ìš”. ì´ì œ ì¤‘ê°„ ëª©í‘œ 3ê°€ì§€ë¥¼ ì œì‹œí•´ë“œë¦´ê²Œìš”."
        # 6ë‹¨ê³„ë¡œ ì´ë™ (OpenAI APIë¡œ ì¤‘ê°„ ëª©í‘œ ìƒì„±)
        midgoals = call_gpt_list(
            prompt=career_midgoal_prompt.format(career=career, reasons=reasons, issue=issues_selected[0], topic=topic, goal=goal),
            system_message="ë„ˆëŠ” ì§„ë¡œ íƒìƒ‰ì„ ë•ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ì•¼. ì‚¬ìš©ìì˜ ìµœì¢… ëª©í‘œë¥¼ ì‹¤í˜„í•˜ê¸° ìœ„í•œ ì¤‘ê°„ ëª©í‘œ 3ê°€ì§€ë¥¼ í•œêµ­ì–´ë¡œ ê°„ê²°í•˜ê²Œ ì œì‹œí•´ì¤˜.",
            max_tokens=1000,
            fallback=["ì¤‘ê°„ ëª©í‘œë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."],
            strip_chars='-â€¢[]1234567890. '
        )
        context.update({"step": 6, "career": career, "reasons": reasons, "issues_selected": issues_selected, "topic": topic, "goal": goal, "midgoals": midgoals, "chatbot_message": chatbot_message})
        return templates.TemplateResponse("career_flow_allinone.html", context)
    # 6ë‹¨ê³„: ì¤‘ê°„ ëª©í‘œ ì œì‹œ ë° ì¬ìƒì„± (ì„ íƒ ì•„ë‹˜, ì œì‹œë§Œ)
    elif step == 6:
        form = await request.form()
        regenerate = form.get("regenerate")
        issues_selected = form.getlist("issues_selected")
        # ì¬ìƒì„± ìš”ì²­ ì‹œ midgoals ìƒˆë¡œ ìƒì„±
        if regenerate == "yes":
            midgoals = call_gpt_list(
                prompt=career_midgoal_prompt.format(career=career, reasons=reasons, issue=issues_selected[0], topic=topic, goal=goal),
                system_message="ë„ˆëŠ” ì§„ë¡œ íƒìƒ‰ì„ ë•ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ì•¼. ì‚¬ìš©ìì˜ ìµœì¢… ëª©í‘œë¥¼ ì‹¤í˜„í•˜ê¸° ìœ„í•œ ì¤‘ê°„ ëª©í‘œ 3ê°€ì§€ë¥¼ í•œêµ­ì–´ë¡œ ê°„ê²°í•˜ê²Œ ì œì‹œí•´ì¤˜.",
                max_tokens=1000,
                fallback=["ì¤‘ê°„ ëª©í‘œë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."],
                strip_chars='-â€¢[]1234567890. '
            )
            chatbot_message = "ì•„ë˜ì™€ ê°™ì´ ìƒˆë¡­ê²Œ ì¤‘ê°„ ëª©í‘œë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ë§ˆìŒì— ë“¤ì§€ ì•Šìœ¼ë©´ ë‹¤ì‹œ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            context.update({"step": 6, "career": career, "reasons": reasons, "issues_selected": issues_selected, "topic": topic, "goal": goal, "midgoals": midgoals, "chatbot_message": chatbot_message})
            return templates.TemplateResponse("career_flow_allinone.html", context)
        
        # "ë‹¤ìŒ" ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ 7ë‹¨ê³„ë¡œ ì´ë™
        chatbot_message = "ë“œë¦¼ë¡œì§ì´ ëª¨ë‘ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ì•„ë˜ëŠ” ë‹¹ì‹ ì˜ ì§„ë¡œ íƒìƒ‰ ê²°ê³¼ì…ë‹ˆë‹¤."
        # ìµœì¢… ìš”ì•½ ìƒì„±
        final_summary_text = call_gpt_list(
            prompt=career_final_summary_prompt.format(
                career=career, 
                reasons=reasons, 
                issue=issues_selected[0] if issues_selected else "", 
                topic=topic, 
                goal=goal, 
                midgoals=midgoals
            ),
            system_message="ë„ˆëŠ” ì§„ë¡œ íƒìƒ‰ì„ ë•ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ì•¼. ì‚¬ìš©ìì˜ ì§„ë¡œ íƒìƒ‰ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ ì²´ê³„ì ìœ¼ë¡œ ì •ë¦¬í•´ì¤˜. ìµœì¢…ëª©í‘œ, ì¤‘ê°„ëª©í‘œ, ì‹¤ì²œí™œë™ì—ë§Œ ì´ëª¨ì§€ë¥¼ ì‚¬ìš©í•˜ê³ , ì œí•œì¡°ê±´ì€ ê²°ê³¼ì— í‘œì‹œí•˜ì§€ ë§ê³  ë‚´ë¶€ì ìœ¼ë¡œë§Œ ì°¸ê³ í•´ì„œ ì‘ì„±í•´ì¤˜.",
            max_tokens=2000,
            fallback=["ìµœì¢… ìš”ì•½ì„ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."],
            strip_chars=''
        )
        final_summary = '\n'.join(final_summary_text) if final_summary_text else "ìµœì¢… ìš”ì•½ì„ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
        
        context.update({
            "step": 7, 
            "career": career, 
            "reasons": reasons, 
            "issues_selected": issues_selected, 
            "topic": topic, 
            "goal": goal, 
            "midgoals": midgoals,
            "final_summary": final_summary,
            "chatbot_message": chatbot_message
        })
        return templates.TemplateResponse("career_flow_allinone.html", context)
        
    # 7ë‹¨ê³„: ìµœì¢… í†µí•© ìš”ì•½ ì¬ìƒì„±
    elif step == 7:
        form = await request.form()
        regenerate = form.get("regenerate")
        issues_selected = form.getlist("issues_selected")
        
        # ì¬ìƒì„± ìš”ì²­ ì‹œì—ë§Œ ì²˜ë¦¬
        if regenerate == "yes":
            # ìµœì¢… ìš”ì•½ ì¬ìƒì„±
            final_summary_text = call_gpt_list(
                prompt=career_final_summary_prompt.format(
                    career=career, 
                    reasons=reasons, 
                    issue=issues_selected[0] if issues_selected else "", 
                    topic=topic, 
                    goal=goal, 
                    midgoals=midgoals
                ),
                system_message="ë„ˆëŠ” ì§„ë¡œ íƒìƒ‰ì„ ë•ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ì•¼. ì‚¬ìš©ìì˜ ì§„ë¡œ íƒìƒ‰ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ ì²´ê³„ì ìœ¼ë¡œ ì •ë¦¬í•´ì¤˜. ìµœì¢…ëª©í‘œ, ì¤‘ê°„ëª©í‘œ, ì‹¤ì²œí™œë™ì—ë§Œ ì´ëª¨ì§€ë¥¼ ì‚¬ìš©í•˜ê³ , ì œí•œì¡°ê±´ì€ ê²°ê³¼ì— í‘œì‹œí•˜ì§€ ë§ê³  ë‚´ë¶€ì ìœ¼ë¡œë§Œ ì°¸ê³ í•´ì„œ ì‘ì„±í•´ì¤˜.",
                max_tokens=2000,
                fallback=["ìµœì¢… ìš”ì•½ì„ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."],
                strip_chars=''
            )
            final_summary = '\n'.join(final_summary_text) if final_summary_text else "ìµœì¢… ìš”ì•½ì„ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
            
            chatbot_message = "ì•„ë˜ì™€ ê°™ì´ ìƒˆë¡­ê²Œ ìµœì¢… ìš”ì•½ì„ ì œì•ˆí•©ë‹ˆë‹¤."
            context.update({
                "step": 7, 
                "career": career, 
                "reasons": reasons, 
                "issues_selected": issues_selected, 
                "topic": topic, 
                "goal": goal, 
                "midgoals": midgoals,
                "final_summary": final_summary,
                "chatbot_message": chatbot_message
            })
            return templates.TemplateResponse("career_flow_allinone.html", context)

def call_gpt_list(prompt, system_message, max_tokens=1000, fallback=None, strip_chars='-â€¢[]1234567890. '):
    """
    GPT-4 Turboë¡œ ë¦¬ìŠ¤íŠ¸ í˜•íƒœì˜ ì‘ë‹µì„ ë°›ì•„ íŒŒì‹±í•˜ëŠ” í—¬í¼ í•¨ìˆ˜
    """
    try:
        chat_completion = client.chat.completions.create(
            model="gpt-4.1-mini",
            messages=[
                {"role": "system", "content": system_message},
                {"role": "user", "content": prompt},
            ],
            max_tokens=max_tokens
        )
        content = chat_completion.choices[0].message.content or ""
        lines = content.split('\n')
        
        # ì„¤ëª… ë¬¸ì¥ ì œê±°: ì½œë¡ (:)ì´ í¬í•¨ëœ ì²« ë²ˆì§¸ ì¤„ë“¤ì€ ì œì™¸
        items = []
        for line in lines:
            line = line.strip()
            if not line:  # ë¹ˆ ì¤„ ê±´ë„ˆë›°ê¸°
                continue
            # ì„¤ëª… ë¬¸ì¥ íŒ¨í„´ ì œê±° (ì½œë¡ ì´ í¬í•¨ë˜ê³  "ê°€ì§€", "ì…ë‹ˆë‹¤", "ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤" ë“±ì´ í¬í•¨ëœ ê²½ìš°)
            if ':' in line and any(word in line for word in ['ê°€ì§€', 'ì…ë‹ˆë‹¤', 'ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤', 'ì œì‹œ', 'ê´€ë ¨ëœ']):
                continue
            # strip_charsë¡œ ë¶ˆí•„ìš”í•œ ë¬¸ì ì œê±°
            cleaned_line = line.strip(strip_chars).strip()
            if cleaned_line:  # ì •ë¦¬ëœ í›„ì—ë„ ë‚´ìš©ì´ ìˆìœ¼ë©´ ì¶”ê°€
                items.append(cleaned_line)
        
        if not items and fallback:
            items = fallback
        return items
    except Exception as e:
        return [f"ì—ëŸ¬: {str(e)}"] + (fallback if fallback else [])

