# FastAPI ê¸°ë³¸ í˜•ì„ ì‘ì„±í•´ ì£¼ì„¸ìš”. ê°€ì¥ ê¸°ë³¸ì´ ë˜ëŠ” app ì™€ '/' url ì•  ëŒ€í•œ ì‚¬í•­ë§Œ ì ìš©í•¨
from fastapi import FastAPI, Request, Form
from fastapi.responses import HTMLResponse, RedirectResponse, FileResponse
from fastapi.templating import Jinja2Templates
from fastapi.staticfiles import StaticFiles
from typing import List, Optional
# openai ì˜ OpenAI APIë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ import
from openai import OpenAI
# python-dotenvë¥¼ ì‚¬ìš©í•˜ì—¬ í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
from dotenv import load_dotenv
import os
from datetime import datetime
import tempfile
# PDF ìƒì„±ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
from reportlab.lib.pagesizes import A4
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.lib.units import inch
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer
from reportlab.pdfbase import pdfmetrics
from reportlab.pdfbase.ttfonts import TTFont


# OpenAI API í‚¤ ì„¤ì •
load_dotenv()
_key = os.getenv("OPENAI_API_KEY")
#openai.api_key = _key
client = OpenAI(api_key=_key) # Or it will pick from environment variable
GPT_MODEL = "gpt-5"  # GPT-4.1 ëª¨ë¸ (ë¹ ë¥´ê³  íš¨ìœ¨ì )
app = FastAPI()
templates_dir = os.path.join(os.path.dirname(__file__), "templates")
templates = Jinja2Templates(directory=templates_dir)
# ì •ì  íŒŒì¼(static) ê²½ë¡œ ë“±ë¡
import os
static_dir = os.path.join(os.path.dirname(__file__), "static")
app.mount("/static", StaticFiles(directory=static_dir), name="static")

@app.get("/")
async def index():
    return RedirectResponse(url="/career/flow")

# ì§„ë¡œ íƒìƒ‰ì„ ìœ„í•œ career ëª©ë¡ì„ ì €ì¥í•˜ê¸° ìœ„í•œ ë°ì´í„° êµ¬ì¡°
# ì§„ë¡œ íƒìƒ‰ 1ë‹¨ê³„ ì›í•˜ëŠ” ì§ì—…ì„ íƒ

# íŒŒì´ì¬ ë¦¬ìŠ¤íŠ¸ í˜•ì‹ì˜ ìë£Œêµ¬ì¡° ë¥¼ ì‚¬ìš©í•˜ì—¬ career ëª©ë¡ì„ ì €ì¥
# ì§„ë¡œ ê°€ì¹˜ íƒìƒ‰ 2ë‹¨ê³„ í”„ë¡¬í”„íŠ¸ì™€ ì„ íƒì§€ë¥¼ ë¦¬ìŠ¤íŠ¸ êµ¬ì¡°ë¡œ ì •ì˜
career_value_prompt = "2ë‹¨ê³„ ì™œ ì´ {career} ì„ í¬ë§í•˜ë‚˜ìš”? (ë³µìˆ˜ ì„ íƒ ê°€ëŠ¥)"
career_value_choices = [
    {"id": 1, "label": "ê²½ì œì  ê°€ì¹˜", "description": "ë†’ì€ ìˆ˜ì…, ì•ˆì •ì ì¸ ì§ì—…"},
    {"id": 2, "label": "ì‚¬íšŒì  ê°€ì¹˜", "description": "ì‚¬íšŒì— ê¸ì •ì ì¸ ì˜í–¥, ë´‰ì‚¬"},
    {"id": 3, "label": "ê³µë™ì²´ì  ê°€ì¹˜", "description": "ì‚¬ëŒë“¤ê³¼ í˜‘ë ¥, ì†Œí†µ"},
    {"id": 4, "label": "ëŠ¥ë ¥ ë°œíœ˜", "description": "ë‚˜ì˜ ì¬ëŠ¥ê³¼ ì—­ëŸ‰ì„ ìµœëŒ€í•œ ë°œíœ˜"},
    {"id": 5, "label": "ììœ¨Â·ì°½ì˜ì„±", "description": "ë…ë¦½ì ìœ¼ë¡œ ì¼í•˜ê³  ìƒˆë¡œìš´ ì•„ì´ë””ì–´ ì°½ì¶œ"},
    {"id": 6, "label": "ë¯¸ë˜ ë¹„ì „", "description": "ì„±ì¥ ê°€ëŠ¥ì„±, í˜ì‹ ì ì¸ ë¶„ì•¼"},
]

# ì§„ë¡œ ê°€ì¹˜ íƒìƒ‰ 3ë‹¨ê³„ í”„ë¡¬í”„íŠ¸ ì •ì˜ (ì„ íƒì§€ëŠ” ì˜ˆì‹œë¡œë§Œ ì£¼ì„ì— ëª…ì‹œ, ì‹¤ì œë¡œëŠ” ë§¤ë²ˆ ìƒì„±)
career_issue_prompt = (
    """
    3ë‹¨ê³„.
    ë‹¹ì‹ ì´ ì„ íƒí•œ '{career}' ì§ì—…ê³¼ ê´€ë ¨ëœ ìµœì‹  ì´ìŠˆ ë˜ëŠ” í•´ê²° ê³¼ì œ ì¤‘ ê°€ì¥ ê´€ì‹¬ ìˆëŠ” ê²ƒì€ 5ê°€ì§€ ì œì‹œí•´ ì£¼ì„¸ìš”.
    # ì˜ˆì‹œ: ê¸°í›„ ìœ„ê¸°ì— ëŒ€ì‘í•˜ëŠ” ì§€ì† ê°€ëŠ¥í•œ ê±´ì¶• ê¸°ìˆ  ë¶€ì¡±, ê³ ë ¹í™” ì‚¬íšŒì˜ ëŒë´„ ì‹œìŠ¤í…œ ê°œì„ , ì¸ê³µì§€ëŠ¥ ìœ¤ë¦¬ ë¬¸ì œ í•´ê²°,
    # ë””ì§€í„¸ ê²©ì°¨ í•´ì†Œ ë°©ì•ˆ, ë¬¸í™” ì½˜í…ì¸ ì˜ ê¸€ë¡œë²Œ ê²½ìŸë ¥ ê°•í™”
    """
)
# ì‹¤ì œ ì„ íƒì§€ëŠ” OpenAI APIë¥¼ í†µí•´ careerì— ë”°ë¼ ë™ì ìœ¼ë¡œ ìƒì„±

# ì§„ë¡œ ê°€ì¹˜ íƒìƒ‰ 4ë‹¨ê³„ í”„ë¡¬í”„íŠ¸ ì •ì˜ (ì„ íƒì§€ëŠ” ì˜ˆì‹œë¡œë§Œ ì£¼ì„ì— ëª…ì‹œ, ì‹¤ì œë¡œëŠ” ë§¤ë²ˆ ìƒì„±)
career_topic_prompt = (
    """
    4ë‹¨ê³„.
    ì•ì„œ ì„ íƒí•œ '{career}' ì§ì—…ê³¼ ê´€ë ¨ëœ ì´ìŠˆ ì¤‘ '{issue}' ì´ìŠˆì— ëŒ€í•´ 
    ì„ íƒëœ ë¬¸ì œì— ëŒ€í•´ êµ¬ì²´ì ìœ¼ë¡œ íƒêµ¬ ê°€ëŠ¥í•œ ì£¼ì œ 5ê°€ì§€ ì œì‹œí•´ì£¼ì„¸ìš”.
    # ê¸°ìˆ /ì •ì±…/ì‹¬ë¦¬/êµìœ¡/ë°ì´í„° ë¶„ì„ ë“± ë‹¤ì–‘í•œ ë°©ë²•ë¡  ì œì‹œ
    # ì¤‘ë³µ ì—†ì´ ìƒˆë¡œìš´ ì‹œì„  ê°•ì¡°
    """
)

# ì§„ë¡œ ê°€ì¹˜ íƒìƒ‰ 5ë‹¨ê³„ í”„ë¡¬í”„íŠ¸ ì •ì˜ (ì„ íƒì§€ëŠ” ì˜ˆì‹œë¡œë§Œ ì£¼ì„ì— ëª…ì‹œ, ì‹¤ì œë¡œëŠ” ë§¤ë²ˆ ìƒì„±)
career_goal_prompt = (
    """
    5ë‹¨ê³„.
    ì§€ê¸ˆê¹Œì§€ ì„ íƒí•œ ì§ì—…: '{career}', ì´ìœ : {reasons}, ì´ìŠˆ: '{issue}', íƒêµ¬ ì£¼ì œ: '{topic}'ë¥¼ ë°”íƒ•ìœ¼ë¡œ
    ì‚¬ìš©ìì—ê²Œ ì§„ë¡œ ëª©í‘œë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ ì œì‹œí•´ ì£¼ì„¸ìš”.
    {reasons} ì—ì„œ ì„ íƒí•œ ê°’ì„ ì°¸ê³ í•´ì„œ ê°€ì¹˜ê´€ì´ ì˜ ë“œëŸ¬ë‚˜ë„ë¡ êµ¬ì²´ì ìœ¼ë¡œ í‘œí˜„í•´ ì£¼ì„¸ìš”.
    # ì˜ˆì‹œ: 'ê¸°í›„ ìœ„ê¸° ëŒ€ì‘ì„ ìœ„í•œ ì¹œí™˜ê²½ ê±´ì¶• ì‹œìŠ¤í…œì„ ì„¤ê³„í•˜ì—¬ ì§€ì†ê°€ëŠ¥í•œ ë¯¸ë˜ ì£¼ê±° í˜•íƒœë¥¼ ì‹¤í˜„í•˜ëŠ” ê²ƒ
    """
)

# ì§„ë¡œ ê°€ì¹˜ íƒìƒ‰ 6ë‹¨ê³„ í”„ë¡¬í”„íŠ¸ ì •ì˜ (ì„ íƒì§€ëŠ” ì˜ˆì‹œë¡œë§Œ ì£¼ì„ì— ëª…ì‹œ, ì‹¤ì œë¡œëŠ” ë§¤ë²ˆ ìƒì„±)
career_midgoal_prompt = (
    """
    6ë‹¨ê³„.
    ì§€ê¸ˆê¹Œì§€ ì„ íƒí•œ ì§ì—…: '{career}', ì´ìœ : {reasons}, ì´ìŠˆ: '{issue}', íƒêµ¬ ì£¼ì œ: '{topic}', ìµœì¢… ëª©í‘œ: '{goal}'ì„(ë¥¼) ë°”íƒ•ìœ¼ë¡œ
    ìµœì¢… ëª©í‘œë¥¼ ì‹¤í˜„í•˜ê¸° ìœ„í•´ ê³ ë“±í•™ìƒ ìˆ˜ì¤€ì—ì„œ ê¸¸ëŸ¬ì•¼ í•  í•µì‹¬ ì—­ëŸ‰ ê¸°ë°˜ ì¤‘ê°„ ëª©í‘œ 3ê°œë¥¼ ì œì‹œí•´ ì£¼ì„¸ìš”
    
    [1] í•™ì—…ì—­ëŸ‰ì„ í¬í•¨í•˜ëŠ” ë‚´ìš©ìœ¼ë¡œ ì œì‹œ
    [2] ì§„ë¡œì—­ëŸ‰ë¥¼ í¬í•¨í•˜ëŠ” ë‚´ìš©ìœ¼ë¡œ ì œì‹œ
    [3] ê³µë™ì²´ì—­ëŸ‰ë¥¼ í¬í•¨í•˜ëŠ” ë‚´ìš©ìœ¼ë¡œ ì œì‹œ
    # ì˜ˆì‹œ: ì¹œí™˜ê²½ ê¸°ìˆ  ì—­ëŸ‰ ê°•í™” / ì„¤ê³„ ëŠ¥ë ¥ í–¥ìƒ / ê³µë™ì²´ì  ì‹¤ì²œì˜ì‹ í•¨ì–‘
    """
)

# ì§„ë¡œ ê°€ì¹˜ íƒìƒ‰ 7ë‹¨ê³„ í”„ë¡¬í”„íŠ¸ ì •ì˜ (ìµœì¢… í†µí•© ì •ë¦¬)
career_final_summary_prompt = (
    """
    7ë‹¨ê³„.
    ì§€ê¸ˆê¹Œì§€ ì„ íƒí•œ ì§ì—…: '{career}', ì´ìœ : {reasons}, ì´ìŠˆ: '{issue}', íƒêµ¬ ì£¼ì œ: '{topic}',
    ìµœì¢… ëª©í‘œ: '{goal}', ì¤‘ê°„ ëª©í‘œ: {midgoals}, ì„(ë¥¼) ë°”íƒ•ìœ¼ë¡œ ì•„ë˜ í˜•ì‹ìœ¼ë¡œ ëª¨ë“  ë‚´ìš©ì„ ëŒ€í•œë¯¼êµ­ ê³ ë“±í•™êµì—ì„œ ìˆ˜í–‰í•  ìˆ˜ ìˆëŠ” ìˆ˜ì¤€ì—ì„œ í†µí•©í•˜ì—¬ ì •ë¦¬í•´ ì£¼ì„¸ìš”.
    ìµœì¢…ëª©í‘œ, ì¤‘ê°„ëª©í‘œ, ì‹¤ì²œí™œë™ì—ë§Œ ì´ëª¨ì§€ë¥¼ ì‚¬ìš©í•´ì„œ ì‹œê°ì ìœ¼ë¡œ ë§¤ë ¥ì ì´ê³  ì½ê¸° ì‰½ê²Œ ë§Œë“¤ì–´ì£¼ì„¸ìš”.
    ì œí•œì¡°ê±´ì€ ê²°ê³¼ì— í‘œì‹œí•˜ì§€ ë§ê³  ë‚´ë¶€ì ìœ¼ë¡œë§Œ ì°¸ê³ í•˜ì„¸ìš”:
    ì•„ë˜ëŠ” ê±´ì¶•ê°€ë¥¼ í¬ë§í•˜ëŠ” ê³ ë“±í•™ìƒì˜ ì§„ë¡œ íƒìƒ‰ ê²°ê³¼ ì˜ˆì‹œì…ë‹ˆë‹¤.
    
    # ì˜ˆì‹œ:
        ğŸ¯ [ìµœì¢… ëª©í‘œ(ê¿ˆ)] ê¸°í›„ ìœ„ê¸° ëŒ€ì‘ì„ ìœ„í•œ ì¹œí™˜ê²½ ê±´ì¶• ì‹œìŠ¤í…œ ì„¤ê³„í•˜ì—¬ ì§€ì†ê°€ëŠ¥í•œ ë¯¸ë˜ ì£¼ê±° í˜•íƒœë¥¼ ì‹¤í˜„í•˜ëŠ” ê±´ì¶•ê°€

        ğŸ“š [ì¤‘ê°„ëª©í‘œ1] ì¹œí™˜ê²½ ê±´ì¶• ê¸°ìˆ  ì—­ëŸ‰
        ğŸ”¬ ì‹¤ì²œí™œë™1:
                    íƒêµ¬ë³´ê³ ì„œ: "ì œë¡œì—ë„ˆì§€ ê±´ì¶• ê¸°ìˆ ì˜ ì‹¤ì œ ì ìš© ì‚¬ë¡€ ë¶„ì„" ë“±
                    êµê³¼ í™œë™: ê³µí†µ ê³¼í•™ - 'ì—ë„ˆì§€ ì „í™˜' ë‹¨ì› [ì‹¬í™”]
                    ë¹„êµê³¼: ì—ë„ˆì§€ ì°½ì˜ ì„¤ê³„ ìº í”„ ì°¸ê°€ - [ë¬¸ì œ í•´ê²°ë ¥ ì„±ì¥ê³¼ ê´€ë ¨]
        ğŸ”¬ ì‹¤ì²œí™œë™2:
                    íƒêµ¬ë³´ê³ ì„œ:
                    êµê³¼ í™œë™: ìƒëª…
                    ë¹„êµê³¼:
        ğŸ”¬ ì‹¤ì²œí™œë™3:
                    íƒêµ¬ë³´ê³ ì„œ:  
                    êµê³¼ í™œë™: ìœ ì „ìì™€~~
                    ë¹„êµê³¼:  
        
        ğŸ¨ [ì¤‘ê°„ëª©í‘œ2] ì„¤ê³„ ëŠ¥ë ¥ í–¥ìƒ
        ğŸ”¬ ì‹¤ì²œí™œë™1:
                    íƒêµ¬ë³´ê³ ì„œ: "ê±´ì¶• ì„¤ê³„ì˜ ê¸°ì´ˆì™€ ì‹¤ì œ" ë“±
                    êµê³¼ í™œë™: ê³µí†µ ê¸°ìˆ  - 'ê¸°ì´ˆ ì„¤ê³„ ì›ë¦¬'
                    ë¹„êµê³¼: ê±´ì¶• ì„¤ê³„ ì›Œí¬ìˆ ì°¸ê°€ - [ì°½ì˜ì  ë¬¸ì œ í•´ê²°ë ¥ ì„±ì¥ê³¼ ê´€ë ¨]
        ğŸ”¬ ì‹¤ì²œí™œë™2:
                    íƒêµ¬ë³´ê³ ì„œ: "ê±´ì¶• ì„¤ê³„ì˜ ê¸°ì´ˆì™€ ì‹¤ì œ" ë“±
                    êµê³¼ í™œë™: ê³µí†µ ê¸°ìˆ  - 'ê³ ê¸‰ ì„¤ê³„ ê¸°ë²•'
                    ë¹„êµê³¼: ê±´ì¶• ì„¤ê³„ ê²½ì§„ëŒ€íšŒ ì°¸ê°€ - [ì°½ì˜ì  ë¬¸ì œ í•´ê²°ë ¥ ì„±ì¥ê³¼ ê´€ë ¨]
        ğŸ”¬ ì‹¤ì²œí™œë™3:
                    íƒêµ¬ë³´ê³ ì„œ: "ê±´ì¶• ì„¤ê³„ì˜ ê¸°ì´ˆì™€ ì‹¤ì œ" ë“±
                    êµê³¼ í™œë™: ê³µí†µ ê¸°ìˆ  - 'ê±´ì¶• ì„¤ê³„ í”„ë¡œì íŠ¸'
                    ë¹„êµê³¼: ê±´ì¶• ì„¤ê³„ í”„ë¡œì íŠ¸ ë°œí‘œíšŒ ì°¸ê°€ - [ì°½ì˜ì  ë¬¸ì œ í•´ê²°ë ¥ ì„±ì¥ê³¼ ê´€ë ¨]
        
        ğŸ¤ [ì¤‘ê°„ëª©í‘œ3] ê³µë™ì²´ì  ì‹¤ì²œì˜ì‹ í•¨ì–‘
        ğŸ”¬ ì‹¤ì²œí™œë™1:
        
        ì œí•œ ì¡°ê±´ (ê²°ê³¼ì— í‘œì‹œí•˜ì§€ ë§ê³  ë‚´ë¶€ì ìœ¼ë¡œë§Œ ì°¸ê³ ):
        1. í•™ë…„ë³„ êµê³¼ í™œë™ì˜ ê²½ìš° '2022 êµìœ¡ê°œí¸ì¤‘ ê³ ë“±í•™êµ êµìœ¡ê³¼ì •' ë°˜ì˜í•˜ì—¬ í™œë™ ì œì‹œ
        2. í•™êµì™¸ì— ëŒ€íšŒë‚˜ ê³µëª¨ì „ì€ ì–¸ê¸‰í•˜ì§€ ì•Šê¸°. í•™êµì—ì„œ ì´ë£¨ì–´ì§ˆ ìˆ˜ ìˆëŠ” í™œë™ìœ¼ë¡œë§Œ ì‹¤ì²œí™œë™ ì œì‹œí•˜ê¸°
        3. ìì†Œì„œ ë“±ì€ ì–¸ê¸‰í•˜ì§€ ì•Šê¸°
        4. ê³ ë“±í•™ìƒ ìˆ˜ì¤€ì—ì„œ ì´í•´ í•  ìˆ˜ ìˆëŠ” íƒêµ¬í™œë™ ì£¼ì œ ì œì‹œ
            "ê° í•­ëª©ì€ ì‹¤ì œ ì…ë ¥ê°’ì— ë§ê²Œ êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”."
    """
)



@app.get("/career/flow", response_class=HTMLResponse)
async def career_flow_get(request: Request):
    now = datetime.now().timestamp()
    return templates.TemplateResponse("career_flow_allinone.html", {"request": request, "step": 1, "start_time": now, "step_start_time": now})

@app.post("/career/flow", response_class=HTMLResponse)
async def career_flow_post(
    request: Request,
    step: int = Form(1),
    career: Optional[str] = Form(None),
    reasons: Optional[List[str]] = Form(None),
    issue: Optional[str] = Form(None),
    topic: Optional[str] = Form(None),
    goal: Optional[str] = Form(None),
    midgoals: Optional[List[str]] = Form(None),
    midgoal_details: Optional[str] = Form(None),
    practices: Optional[str] = Form(None),
    start_time: Optional[float] = Form(None),
    step_start_time: Optional[float] = Form(None),
):
    now = datetime.now().timestamp()
    context = {"request": request, "step": step}
    # start_time ê´€ë¦¬
    if not start_time:
        start_time = now
    context["start_time"] = start_time
    # step_start_time ê´€ë¦¬ (ë‹¨ê³„ë³„ ì†Œìš” ì‹œê°„ ì‚­ì œ, current_step_timeë„ ì‚­ì œ)
    if not step_start_time:
        step_start_time = now
    context["step_start_time"] = step_start_time
    chatbot_message = None
    # 1ë‹¨ê³„: ì§ì—… ì…ë ¥
    if step == 1:
        if not career:
            context.update({"error": "ì§ì—…ì„ ì…ë ¥í•˜ì„¸ìš”."})
            return templates.TemplateResponse("career_flow_allinone.html", context)
        choices = career_value_choices
        chatbot_message = f"'{career}'(ì„)ë¥¼ ì„ íƒí•˜ì…¨êµ°ìš”. ì´ ì§ì—…ì„ ì„ íƒí•œ ì´ìœ ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”!"
        context.update({"step": 2, "career": career, "choices": choices, "chatbot_message": chatbot_message})
        return templates.TemplateResponse("career_flow_allinone.html", context)
    # 2ë‹¨ê³„: ì´ìœ  ë³µìˆ˜ ì„ íƒ
    elif step == 2:
        if not (career and reasons):
            context.update({"step": 2, "career": career, "choices": career_value_choices, "error": "ì´ìœ ë¥¼ í•œ ê°€ì§€ ì´ìƒ ì„ íƒí•˜ì„¸ìš”."})
            return templates.TemplateResponse("career_flow_allinone.html", context)
        chatbot_message = f"{', '.join(reasons)}(ì„)ë¥¼ ì„ íƒí•˜ì…¨êµ°ìš”. ì´ì œ {career}ì™€ ê´€ë ¨ëœ ìµœì‹  ì´ìŠˆë¥¼ ê³¨ë¼ë³¼ê¹Œìš”?"
        # 3ë‹¨ê³„ë¡œ ì´ë™ (OpenAI APIë¡œ ì´ìŠˆ ìƒì„±)
        issues = call_gpt_list(
            prompt=career_issue_prompt.format(career=career),
            system_message="ë„ˆëŠ” ì§„ë¡œ íƒìƒ‰ì„ ë•ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ì•¼. ì‚¬ìš©ìê°€ ì„ íƒí•œ ì§ì—…ê³¼ ê´€ë ¨ëœ ìµœì‹  ì´ìŠˆë‚˜ í•´ê²° ê³¼ì œ 5ê°€ì§€ë¥¼ í•œêµ­ì–´ë¡œ ê°„ê²°í•˜ê²Œ ì œì‹œí•´ì¤˜.",
            max_completion_tokens=1000,
            fallback=["ì´ìŠˆë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."],
            strip_chars='-â€¢ '
        )
        context.update({"step": 3, "career": career, "reasons": reasons, "issues": issues, "chatbot_message": chatbot_message})
        return templates.TemplateResponse("career_flow_allinone.html", context)
    # 3ë‹¨ê³„: ì´ìŠˆ ì„ íƒ
    elif step == 3:
        form = await request.form()
        regenerate = form.get("regenerate")
        # ë‹¤ì¤‘ ì„ íƒ ì§€ì›: issuesëŠ” ë¦¬ìŠ¤íŠ¸
        issues_selected = [str(x) for x in form.getlist("issues")]
        # 'ë‹¤ì‹œ ìƒì„±' ë²„íŠ¼ ì²˜ë¦¬
        if regenerate == "yes":
            issues = call_gpt_list(
                prompt=career_issue_prompt.format(career=career),
                system_message="ë„ˆëŠ” ì§„ë¡œ íƒìƒ‰ì„ ë•ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ì•¼. ì‚¬ìš©ìê°€ ì„ íƒí•œ ì§ì—…ê³¼ ê´€ë ¨ëœ ìµœì‹  ì´ìŠˆë‚˜ í•´ê²° ê³¼ì œ 5ê°€ì§€ë¥¼ í•œêµ­ì–´ë¡œ ê°„ê²°í•˜ê²Œ ì œì‹œí•´ì¤˜.",
                max_completion_tokens=1000,
                fallback=["ì´ìŠˆë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."],
                strip_chars='-â€¢ '
            )
            chatbot_message = f"ì´ìŠˆë¥¼ ìƒˆë¡œ ì œì•ˆí•©ë‹ˆë‹¤. ì›í•˜ëŠ” ì´ìŠˆë¥¼ ëª¨ë‘ ì„ íƒí•˜ì„¸ìš”."
            context.update({"step": 3, "career": career, "reasons": reasons, "issues": issues, "chatbot_message": chatbot_message, "issues_selected": []})
            return templates.TemplateResponse("career_flow_allinone.html", context)
        if not (career and reasons and issues_selected):
            context.update({"step": 3, "career": career, "reasons": reasons, "issues": context.get("issues", []), "error": "ì´ìŠˆë¥¼ í•œ ê°€ì§€ ì´ìƒ ì„ íƒí•˜ì„¸ìš”.", "issues_selected": issues_selected})
            return templates.TemplateResponse("career_flow_allinone.html", context)
        chatbot_message = f"{', '.join(issues_selected)}(ì„)ë¥¼ ì„ íƒí•˜ì…¨êµ°ìš”. ì´ ì´ìŠˆë“¤ì— ëŒ€í•´ íƒêµ¬í•˜ê³  ì‹¶ì€ ì£¼ì œë¥¼ ê³¨ë¼ì£¼ì„¸ìš”!"
        # 4ë‹¨ê³„ë¡œ ì´ë™ (OpenAI APIë¡œ íƒêµ¬ ì£¼ì œ ìƒì„±, ì²« ë²ˆì§¸ ì´ìŠˆë§Œ ì‚¬ìš©)
        topics = call_gpt_list(
            prompt=career_topic_prompt.format(career=career, issue=issues_selected[0]),
            system_message="ë„ˆëŠ” ì§„ë¡œ íƒìƒ‰ì„ ë•ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ì•¼. ì‚¬ìš©ìê°€ ì„ íƒí•œ ì´ìŠˆì— ëŒ€í•´ êµ¬ì²´ì ìœ¼ë¡œ íƒêµ¬ ê°€ëŠ¥í•œ ì£¼ì œ 3ê°€ì§€ë¥¼ í•œêµ­ì–´ë¡œ ê°„ê²°í•˜ê²Œ ì œì‹œí•´ì¤˜.",
            max_completion_tokens=1000,
            fallback=["ì£¼ì œë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."],
            strip_chars='-â€¢[]1234567890. '
        )
        context.update({"step": 4, "career": career, "reasons": reasons, "issues_selected": issues_selected, "topics": topics, "chatbot_message": chatbot_message})
        return templates.TemplateResponse("career_flow_allinone.html", context)
    # 4ë‹¨ê³„: íƒêµ¬ ì£¼ì œ ì„ íƒ
    elif step == 4:
        form = await request.form()
        regenerate = form.get("regenerate")
        topic = form.get("topic") # type: ignore
        # issues_selectedë¥¼ hidden inputì—ì„œ ë°›ì•„ì˜´
        issues_selected = form.getlist("issues_selected")
        
        # 'ë‹¤ì‹œ ìƒì„±' ë²„íŠ¼ ì²˜ë¦¬
        if regenerate == "yes":
            topics = call_gpt_list(
                prompt=career_topic_prompt.format(career=career, issue=issues_selected[0]),
                system_message="ë„ˆëŠ” ì§„ë¡œ íƒìƒ‰ì„ ë•ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ì•¼. ì‚¬ìš©ìê°€ ì„ íƒí•œ ì´ìŠˆì— ëŒ€í•´ êµ¬ì²´ì ìœ¼ë¡œ íƒêµ¬ ê°€ëŠ¥í•œ ì£¼ì œ 3ê°€ì§€ë¥¼ í•œêµ­ì–´ë¡œ ê°„ê²°í•˜ê²Œ ì œì‹œí•´ì¤˜.",
                max_completion_tokens=1000,
                fallback=["ì£¼ì œë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."],
                strip_chars='-â€¢[]1234567890. '
            )
            chatbot_message = f"ì£¼ì œë¥¼ ìƒˆë¡œ ì œì•ˆí•©ë‹ˆë‹¤. ì›í•˜ëŠ” ì£¼ì œë¥¼ ì„ íƒí•˜ì„¸ìš”."
            context.update({"step": 4, "career": career, "reasons": reasons, "issues_selected": issues_selected, "topics": topics, "chatbot_message": chatbot_message})
            return templates.TemplateResponse("career_flow_allinone.html", context)
        
        # ì£¼ì œ ì„ íƒ ê²€ì¦ (ì¬ìƒì„±ì´ ì•„ë‹Œ ê²½ìš°ì—ë§Œ)
        if not (career and reasons and issues_selected):
            context.update({"step": 4, "career": career, "reasons": reasons, "issues_selected": issues_selected, "topics": ["ì£¼ì œë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."], "error": "ì´ì „ ë‹¨ê³„ ì •ë³´ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤."})
            return templates.TemplateResponse("career_flow_allinone.html", context)
        
        if not topic:
            # ì£¼ì œê°€ ì„ íƒë˜ì§€ ì•Šì€ ê²½ìš°, ê¸°ë³¸ topics ìƒì„±
            topics = call_gpt_list(
                prompt=career_topic_prompt.format(career=career, issue=issues_selected[0]),
                system_message="ë„ˆëŠ” ì§„ë¡œ íƒìƒ‰ì„ ë•ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ì•¼. ì‚¬ìš©ìê°€ ì„ íƒí•œ ì´ìŠˆì— ëŒ€í•´ êµ¬ì²´ì ìœ¼ë¡œ íƒêµ¬ ê°€ëŠ¥í•œ ì£¼ì œ 3ê°€ì§€ë¥¼ í•œêµ­ì–´ë¡œ ê°„ê²°í•˜ê²Œ ì œì‹œí•´ì¤˜.",
                max_completion_tokens=1000,
                fallback=["ì£¼ì œë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."],
                strip_chars='-â€¢[]1234567890. '
            )
            context.update({"step": 4, "career": career, "reasons": reasons, "issues_selected": issues_selected, "topics": topics, "error": "ì£¼ì œë¥¼ ì„ íƒí•˜ì„¸ìš”."})
            return templates.TemplateResponse("career_flow_allinone.html", context)
        # 5ë‹¨ê³„: GPTê°€ ì œì‹œí•˜ëŠ” ì§„ë¡œ ëª©í‘œ
        suggested_goal = call_gpt_list(
            prompt=career_goal_prompt.format(career=career, reasons=reasons, issue=issues_selected[0], topic=topic),
            system_message="ë„ˆëŠ” ì§„ë¡œ íƒìƒ‰ì„ ë•ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ì•¼. ì‚¬ìš©ìì˜ ì„ íƒì„ ë°”íƒ•ìœ¼ë¡œ ì ì ˆí•œ ì§„ë¡œ ëª©í‘œë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ ì œì‹œí•´ì¤˜.",
            max_completion_tokens=100,
            fallback=["ì§„ë¡œ ëª©í‘œë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."],
            strip_chars=''  # í•œ ë¬¸ì¥ë§Œ ë°˜í™˜
        )[0]
        chatbot_message = f"ì•„ë˜ì™€ ê°™ì€ ì§„ë¡œ ëª©í‘œë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ë§ˆìŒì— ë“¤ì§€ ì•Šìœ¼ë©´ 'ë‹¤ì‹œ ìƒì„±'ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”."
        context.update({"step": 5, "career": career, "reasons": reasons, "issues_selected": issues_selected, "topic": topic, "suggested_goal": suggested_goal, "chatbot_message": chatbot_message})
        return templates.TemplateResponse("career_flow_allinone.html", context)
    # 5ë‹¨ê³„: ì§„ë¡œ ëª©í‘œ í™•ì¸ ë° ì¬ìƒì„±
    elif step == 5:
        form = await request.form()
        suggested_goal = form.get("suggested_goal")
        regenerate = form.get("regenerate")
        issues_selected = form.getlist("issues_selected")
        if regenerate == "yes":
            # ëª©í‘œ ì¬ìƒì„±
            suggested_goal = call_gpt_list(
                prompt=career_goal_prompt.format(career=career, reasons=reasons, issue=issues_selected[0], topic=topic),
                system_message="ë„ˆëŠ” ì§„ë¡œ íƒìƒ‰ì„ ë•ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ì•¼. ì‚¬ìš©ìì˜ ì„ íƒì„ ë°”íƒ•ìœ¼ë¡œ ì ì ˆí•œ ì§„ë¡œ ëª©í‘œë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ ì œì‹œí•´ì¤˜.",
                max_completion_tokens=100,
                fallback=["ì§„ë¡œ ëª©í‘œë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."],
                strip_chars=''
            )[0]
            chatbot_message = "ì•„ë˜ì™€ ê°™ì´ ìƒˆë¡­ê²Œ ì§„ë¡œ ëª©í‘œë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ë§ˆìŒì— ë“¤ì§€ ì•Šìœ¼ë©´ ë‹¤ì‹œ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            context.update({"step": 5, "career": career, "reasons": reasons, "issues_selected": issues_selected, "topic": topic, "suggested_goal": suggested_goal, "chatbot_message": chatbot_message})
            return templates.TemplateResponse("career_flow_allinone.html", context)
        # ì‚¬ìš©ìê°€ ëª©í‘œë¥¼ ìˆ˜ë½
        goal = str(suggested_goal) if suggested_goal is not None else None
        chatbot_message = f"'{goal}'(ì„)ë¥¼ ëª©í‘œë¡œ í•˜ì…¨êµ°ìš”. ì´ì œ ì¤‘ê°„ ëª©í‘œ 3ê°€ì§€ë¥¼ ì œì‹œí•´ë“œë¦´ê²Œìš”."
        # 6ë‹¨ê³„ë¡œ ì´ë™ (OpenAI APIë¡œ ì¤‘ê°„ ëª©í‘œ ìƒì„±)
        midgoals = call_gpt_list(
            prompt=career_midgoal_prompt.format(career=career, reasons=reasons, issue=issues_selected[0], topic=topic, goal=goal),
            system_message="ë„ˆëŠ” ì§„ë¡œ íƒìƒ‰ì„ ë•ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ì•¼. ì‚¬ìš©ìì˜ ìµœì¢… ëª©í‘œë¥¼ ì‹¤í˜„í•˜ê¸° ìœ„í•œ ì¤‘ê°„ ëª©í‘œ 3ê°€ì§€ë¥¼ í•œêµ­ì–´ë¡œ ê°„ê²°í•˜ê²Œ ì œì‹œí•´ì¤˜.",
            max_completion_tokens=1000,
            fallback=["ì¤‘ê°„ ëª©í‘œë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."],
            strip_chars='-â€¢[]1234567890. '
        )
        context.update({"step": 6, "career": career, "reasons": reasons, "issues_selected": issues_selected, "topic": topic, "goal": goal, "midgoals": midgoals, "chatbot_message": chatbot_message})
        return templates.TemplateResponse("career_flow_allinone.html", context)
    # 6ë‹¨ê³„: ì¤‘ê°„ ëª©í‘œ ì œì‹œ ë° ì¬ìƒì„± (ì„ íƒ ì•„ë‹˜, ì œì‹œë§Œ)
    elif step == 6:
        form = await request.form()
        regenerate = form.get("regenerate")
        issues_selected = form.getlist("issues_selected")
        # ì¬ìƒì„± ìš”ì²­ ì‹œ midgoals ìƒˆë¡œ ìƒì„±
        if regenerate == "yes":
            midgoals = call_gpt_list(
                prompt=career_midgoal_prompt.format(career=career, reasons=reasons, issue=issues_selected[0], topic=topic, goal=goal),
                system_message="ë„ˆëŠ” ì§„ë¡œ íƒìƒ‰ì„ ë•ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ì•¼. ì‚¬ìš©ìì˜ ìµœì¢… ëª©í‘œë¥¼ ì‹¤í˜„í•˜ê¸° ìœ„í•œ ì¤‘ê°„ ëª©í‘œ 3ê°€ì§€ë¥¼ í•œêµ­ì–´ë¡œ ê°„ê²°í•˜ê²Œ ì œì‹œí•´ì¤˜.",
                max_completion_tokens=1000,
                fallback=["ì¤‘ê°„ ëª©í‘œë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."],
                strip_chars='-â€¢[]1234567890. '
            )
            chatbot_message = "ì•„ë˜ì™€ ê°™ì´ ìƒˆë¡­ê²Œ ì¤‘ê°„ ëª©í‘œë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ë§ˆìŒì— ë“¤ì§€ ì•Šìœ¼ë©´ ë‹¤ì‹œ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            context.update({"step": 6, "career": career, "reasons": reasons, "issues_selected": issues_selected, "topic": topic, "goal": goal, "midgoals": midgoals, "chatbot_message": chatbot_message})
            return templates.TemplateResponse("career_flow_allinone.html", context)
        
        # "ë‹¤ìŒ" ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ 7ë‹¨ê³„ë¡œ ì´ë™
        chatbot_message = "ë“œë¦¼ë¡œì§ì´ ëª¨ë‘ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ì•„ë˜ëŠ” ë‹¹ì‹ ì˜ ì§„ë¡œ íƒìƒ‰ ê²°ê³¼ì…ë‹ˆë‹¤."
        # ìµœì¢… ìš”ì•½ ìƒì„±
        final_summary_text = call_gpt_list(
            prompt=career_final_summary_prompt.format(
                career=career, 
                reasons=reasons, 
                issue=issues_selected[0] if issues_selected else "", 
                topic=topic, 
                goal=goal, 
                midgoals=midgoals
            ),
            system_message="ë„ˆëŠ” ì§„ë¡œ íƒìƒ‰ì„ ë•ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ì•¼. ì‚¬ìš©ìì˜ ì§„ë¡œ íƒìƒ‰ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ ì²´ê³„ì ìœ¼ë¡œ ì •ë¦¬í•´ì¤˜. ìµœì¢…ëª©í‘œ, ì¤‘ê°„ëª©í‘œ, ì‹¤ì²œí™œë™ì—ë§Œ ì´ëª¨ì§€ë¥¼ ì‚¬ìš©í•˜ê³ , ì œí•œì¡°ê±´ì€ ê²°ê³¼ì— í‘œì‹œí•˜ì§€ ë§ê³  ë‚´ë¶€ì ìœ¼ë¡œë§Œ ì°¸ê³ í•´ì„œ ì‘ì„±í•´ì¤˜.",
            max_completion_tokens=2000,
            fallback=["ìµœì¢… ìš”ì•½ì„ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."],
            strip_chars=''
        )
        final_summary = '\n'.join(final_summary_text) if final_summary_text else "ìµœì¢… ìš”ì•½ì„ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
        
        context.update({
            "step": 7, 
            "career": career, 
            "reasons": reasons, 
            "issues_selected": issues_selected, 
            "topic": topic, 
            "goal": goal, 
            "midgoals": midgoals,
            "final_summary": final_summary,
            "chatbot_message": chatbot_message
        })
        return templates.TemplateResponse("career_flow_allinone.html", context)
        
    # 7ë‹¨ê³„: ìµœì¢… í†µí•© ìš”ì•½ ì¬ìƒì„±
    elif step == 7:
        form = await request.form()
        regenerate = form.get("regenerate")
        issues_selected = form.getlist("issues_selected")
        
        # ì¬ìƒì„± ìš”ì²­ ì‹œì—ë§Œ ì²˜ë¦¬
        if regenerate == "yes":
            # ìµœì¢… ìš”ì•½ ì¬ìƒì„±
            final_summary_text = call_gpt_list(
                prompt=career_final_summary_prompt.format(
                    career=career, 
                    reasons=reasons, 
                    issue=issues_selected[0] if issues_selected else "", 
                    topic=topic, 
                    goal=goal, 
                    midgoals=midgoals
                ),
                system_message="ë„ˆëŠ” ì§„ë¡œ íƒìƒ‰ì„ ë•ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ì•¼. ì‚¬ìš©ìì˜ ì§„ë¡œ íƒìƒ‰ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ ì²´ê³„ì ìœ¼ë¡œ ì •ë¦¬í•´ì¤˜. ìµœì¢…ëª©í‘œ, ì¤‘ê°„ëª©í‘œ, ì‹¤ì²œí™œë™ì—ë§Œ ì´ëª¨ì§€ë¥¼ ì‚¬ìš©í•˜ê³ , ì œí•œì¡°ê±´ì€ ê²°ê³¼ì— í‘œì‹œí•˜ì§€ ë§ê³  ë‚´ë¶€ì ìœ¼ë¡œë§Œ ì°¸ê³ í•´ì„œ ì‘ì„±í•´ì¤˜.",
                max_completion_tokens=2000,
                fallback=["ìµœì¢… ìš”ì•½ì„ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."],
                strip_chars=''
            )
            final_summary = '\n'.join(final_summary_text) if final_summary_text else "ìµœì¢… ìš”ì•½ì„ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
            
            chatbot_message = "ì•„ë˜ì™€ ê°™ì´ ìƒˆë¡­ê²Œ ìµœì¢… ìš”ì•½ì„ ì œì•ˆí•©ë‹ˆë‹¤."
            context.update({
                "step": 7, 
                "career": career, 
                "reasons": reasons, 
                "issues_selected": issues_selected, 
                "topic": topic, 
                "goal": goal, 
                "midgoals": midgoals,
                "final_summary": final_summary,
                "chatbot_message": chatbot_message
            })
            return templates.TemplateResponse("career_flow_allinone.html", context)


def translate_career_to_english(career_korean):
    """í•œê¸€ ì§ì—…ëª…ì„ ì˜ì–´ë¡œ ë²ˆì—­"""
    try:
        # í•œê¸€ì´ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
        has_korean = any('\uac00' <= char <= '\ud7af' for char in career_korean)
        
        if not has_korean:
            # í•œê¸€ì´ ì—†ìœ¼ë©´ ì˜ì–´ë¡œ ê°„ì£¼í•˜ê³  ì •ë¦¬ë§Œ
            english_career = ''.join(c for c in career_korean if c.isalnum() or c.isspace())
            result = english_career.lower().replace(' ', '_')
            return result
        
        # í•œê¸€ì´ ìˆëŠ” ê²½ìš° OpenAIë¡œ ë²ˆì—­
        chat_completion = client.chat.completions.create(
            model=GPT_MODEL,
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ í•œêµ­ì–´ ì§ì—…ëª…ì„ ì˜ì–´ë¡œ ë²ˆì—­í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì§ì—…ëª…ë§Œ ê°„ë‹¨í•˜ê²Œ ì˜ì–´ë¡œ ë²ˆì—­í•´ì£¼ì„¸ìš”. ë¶€ê°€ ì„¤ëª…ì€ í•˜ì§€ ë§ê³  ì§ì—…ëª…ë§Œ ë‹µë³€í•˜ì„¸ìš”."},
                {"role": "user", "content": f"ë‹¤ìŒ í•œêµ­ì–´ ì§ì—…ëª…ì„ ì˜ì–´ë¡œ ë²ˆì—­í•´ì£¼ì„¸ìš”: {career_korean}"},
            ],
            max_completion_tokens=50
        )
        
        english_career = chat_completion.choices[0].message.content
        if not english_career or not english_career.strip():
            english_career = "unknown_job"
        else:
            english_career = english_career.strip()
        
        # íŠ¹ìˆ˜ë¬¸ì ì œê±°í•˜ê³  ì†Œë¬¸ìë¡œ ë³€í™˜, ê³µë°±ì„ ì–¸ë”ìŠ¤ì½”ì–´ë¡œ
        english_career = ''.join(c for c in english_career if c.isalnum() or c.isspace())
        english_career = english_career.lower().replace(' ', '_')
        
        # ë¹ˆ ë¬¸ìì—´ ì²´í¬
        if not english_career or english_career == '_':
            english_career = "unknown_job"
        
        return english_career
        
    except Exception as e:
        # ë²ˆì—­ ì‹¤íŒ¨ ì‹œ í•œê¸€ì„ ì•ˆì „í•œ í˜•íƒœë¡œ ë³€í™˜
        import re
        safe_career = re.sub(r'[^\w\sê°€-í£]', '', career_korean)
        safe_career = re.sub(r'\s+', '_', safe_career.strip())
        result = f"korean_job_{safe_career}" if safe_career else "unknown_job"
        return result


@app.post("/career/download-pdf")
async def download_pdf(
    career: str = Form(...),
    reasons: List[str] = Form(...),
    issues_selected: List[str] = Form(...),
    topic: str = Form(...),
    goal: str = Form(...),
    midgoals: List[str] = Form(...),
    final_summary: str = Form(...)
):
    """7ë‹¨ê³„ ê²°ê³¼ë¥¼ PDFë¡œ ë‹¤ìš´ë¡œë“œ"""
    try:
        # ì§„ë¡œ ë°ì´í„° êµ¬ì„±
        career_data = {
            'career': career,
            'reasons': reasons,
            'issues_selected': issues_selected,
            'topic': topic,
            'goal': goal,
            'midgoals': midgoals,
            'final_summary': final_summary
        }
        
        # PDF ìƒì„±
        pdf_file = create_pdf_report(career_data)
        
        if pdf_file:
            # ë‹¤ìš´ë¡œë“œ íŒŒì¼ëª… ìƒì„± (í•œê¸€ ì§ì—…ëª…ì„ ì˜ì–´ë¡œ ë²ˆì—­)
            import re
            import urllib.parse
            
            # í•œê¸€ ì§ì—…ëª…ì„ ì˜ì–´ë¡œ ë²ˆì—­
            english_career = translate_career_to_english(career)
            
            # íŒŒì¼ëª…ì„ ì˜ë¬¸ìœ¼ë¡œ ìƒì„± (ë‚ ì§œë§Œ í¬í•¨, ì‹œê°„ ì œì™¸)
            timestamp = datetime.now().strftime('%Y%m%d')
            
            # ë²ˆì—­ëœ ì§ì—…ëª…ì´ ìˆìœ¼ë©´ ì¶”ê°€, ì—†ìœ¼ë©´ ê¸°ë³¸ íŒŒì¼ëª…
            if english_career and english_career.strip():
                filename = f"dreamlogic_career_report_{timestamp}_{english_career}.pdf"
            else:
                filename = f"dreamlogic_career_report_{timestamp}_unknown_job.pdf"
            
            # í•œê¸€ íŒŒì¼ëª…ë„ ìƒì„± (UTF-8 ì¸ì½”ë”©)
            safe_career = re.sub(r'[^\w\sê°€-í£]', '', career)
            safe_career = re.sub(r'\s+', '_', safe_career.strip())
            korean_filename = f"ë“œë¦¼ë¡œì§_ì§„ë¡œíƒìƒ‰ê²°ê³¼_{safe_career}_{timestamp}.pdf"
            encoded_korean_filename = urllib.parse.quote(korean_filename)
            
            # Content-Disposition í—¤ë” ì„¤ì • (ì˜ì–´ íŒŒì¼ëª… + í•œê¸€ íŒŒì¼ëª… ì˜µì…˜)
            return FileResponse(
                pdf_file,
                media_type='application/pdf',
                filename=filename,
                headers={
                    "Content-Disposition": f'attachment; filename="{filename}"; filename*=UTF-8\'\'{encoded_korean_filename}'
                }
            )
        else:
            return HTMLResponse("PDF ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.", status_code=500)
            
    except Exception as e:
        print(f"PDF ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜: {e}")
        return HTMLResponse(f"PDF ë‹¤ìš´ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}", status_code=500)

def call_gpt_list(prompt, system_message, max_completion_tokens=1000, fallback=None, strip_chars='-â€¢[]1234567890. '):
    """
    GPT-4 Turboë¡œ ë¦¬ìŠ¤íŠ¸ í˜•íƒœì˜ ì‘ë‹µì„ ë°›ì•„ íŒŒì‹±í•˜ëŠ” í—¬í¼ í•¨ìˆ˜
    """
    try:
        chat_completion = client.chat.completions.create(
            model=GPT_MODEL,
            messages=[
                {"role": "system", "content": system_message},
                {"role": "user", "content": prompt},
            ],
            max_completion_tokens=max_completion_tokens
        )
        content = chat_completion.choices[0].message.content or ""
        lines = content.split('\n')
        
        # ì„¤ëª… ë¬¸ì¥ ì œê±°: ì½œë¡ (:)ì´ í¬í•¨ëœ ì²« ë²ˆì§¸ ì¤„ë“¤ì€ ì œì™¸
        items = []
        for line in lines:
            line = line.strip()
            if not line:  # ë¹ˆ ì¤„ ê±´ë„ˆë›°ê¸°
                continue
            # ì„¤ëª… ë¬¸ì¥ íŒ¨í„´ ì œê±° (ì½œë¡ ì´ í¬í•¨ë˜ê³  "ê°€ì§€", "ì…ë‹ˆë‹¤", "ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤" ë“±ì´ í¬í•¨ëœ ê²½ìš°)
            if ':' in line and any(word in line for word in ['ê°€ì§€', 'ì…ë‹ˆë‹¤', 'ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤', 'ì œì‹œ', 'ê´€ë ¨ëœ']):
                continue
            # strip_charsë¡œ ë¶ˆí•„ìš”í•œ ë¬¸ì ì œê±°
            cleaned_line = line.strip(strip_chars).strip()
            if cleaned_line:  # ì •ë¦¬ëœ í›„ì—ë„ ë‚´ìš©ì´ ìˆìœ¼ë©´ ì¶”ê°€
                items.append(cleaned_line)
        
        if not items and fallback:
            items = fallback
        return items
    except Exception as e:
        return [f"ì—ëŸ¬: {str(e)}"] + (fallback if fallback else [])


def setup_korean_font():
    """í•œê¸€ í°íŠ¸ ì„¤ì • (ì›¹ í˜¸í™˜ì„± ìš°ì„ )"""
    font_name = 'Helvetica'  # ê¸°ë³¸ê°’
    
    # ì›¹ í˜¸í™˜ í•œê¸€ í°íŠ¸ ê²½ë¡œ (ìš°ì„ ìˆœìœ„)
    font_paths = [
        # 1ìˆœìœ„: ë„¤ì´ë²„ ë‚˜ëˆ”ê³ ë”• (ì›¹ ì„œë¹„ìŠ¤ í˜¸í™˜ì„± ìµœìš°ì„ )
        os.path.join(os.path.dirname(__file__), "fonts", "NanumGothic.ttf"),
        # 2ìˆœìœ„: macOS ì‹œìŠ¤í…œ í°íŠ¸ (ê°œë°œ í™˜ê²½ìš©)
        '/System/Library/Fonts/AppleSDGothicNeo.ttc',
        # 3ìˆœìœ„: Linux í™˜ê²½ì˜ ë‚˜ëˆ”ê³ ë”•
        '/usr/share/fonts/truetype/nanum/NanumGothic.ttf',  # Ubuntu/Debian
        '/usr/share/fonts/nanum-gothic/NanumGothic.ttf',    # CentOS/RHEL
        # 4ìˆœìœ„: Windows í™˜ê²½
        'C:/Windows/Fonts/malgun.ttf',  # ë§‘ì€ ê³ ë”•
    ]
    
    for i, font_path in enumerate(font_paths):
        if os.path.exists(font_path):
            try:
                font_reg_name = f'NanumGothic{i}'
                
                if font_path.endswith('.ttc'):
                    # TTC íŒŒì¼ì˜ ê²½ìš° ì„œë¸Œí°íŠ¸ ì§€ì •
                    pdfmetrics.registerFont(TTFont(font_reg_name, font_path, subfontIndex=0))
                else:
                    # TTF íŒŒì¼
                    pdfmetrics.registerFont(TTFont(font_reg_name, font_path))
                
                font_name = font_reg_name
                print(f"âœ… í°íŠ¸ ë“±ë¡ ì„±ê³µ: {font_path} â†’ {font_name}")
                break
            except Exception as e:
                print(f"âŒ í°íŠ¸ ë“±ë¡ ì‹¤íŒ¨ {font_path}: {e}")
                continue
    
    print(f"ğŸ”¤ ìµœì¢… ì‚¬ìš© í°íŠ¸: {font_name}")
    return font_name


def clean_text_for_pdf(text):
    """PDF í˜¸í™˜ì„±ì„ ìœ„í•œ í…ìŠ¤íŠ¸ ì •ë¦¬"""
    if not text:
        return ""
    
    text = str(text)
    
    # ì´ëª¨ì§€ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
    emoji_map = {
        'ğŸ¯': 'â¦¿',  'ğŸ“š': 'ğŸ“–',  'ğŸ¨': 'ğŸ–¼',  'ğŸ¤': 'ğŸ‘¥',  'ğŸ”¬': 'â€¢',
        'âœ¨': 'â˜…',  'ğŸ ': 'ğŸ˜',  'ğŸ’¼': 'ğŸ‘”',  'ğŸ“': 'âœ',  'ğŸŒŸ': 'â­',
        'ğŸ“…': '[ë‚ ì§œ]', 'ğŸ“': '[êµìœ¡]', 'ğŸ’¡': '[ì•„ì´ë””ì–´]', 'ğŸš€': '[ì‹œì‘]',
        'â¤ï¸': 'â™¥', 'ğŸ‘': '[ì¢‹ìŒ]', 'ğŸ”¥': '[ì¸ê¸°]', 'ğŸ’ª': '[í˜]'
    }
    
    for emoji, replacement in emoji_map.items():
        text = text.replace(emoji, replacement)
    
    # HTML íŠ¹ìˆ˜ë¬¸ì ì²˜ë¦¬
    text = text.replace('&', '&amp;')
    text = text.replace('<', '&lt;')
    text = text.replace('>', '&gt;')
    
    return text


def create_pdf_report(career_data):
    """ì§„ë¡œ íƒìƒ‰ PDF ë³´ê³ ì„œ ìƒì„±"""
    # í•œê¸€ í°íŠ¸ ì„¤ì •
    font_name = setup_korean_font()
    
    # ì„ì‹œ íŒŒì¼ ìƒì„±
    temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.pdf')
    temp_filename = temp_file.name
    temp_file.close()
    
    # PDF ë¬¸ì„œ ìƒì„±
    doc = SimpleDocTemplate(
        temp_filename,
        pagesize=A4,
        leftMargin=inch*0.7,
        rightMargin=inch*0.7,
        topMargin=inch*0.8,
        bottomMargin=inch*0.8
    )
    
    # ìŠ¤íƒ€ì¼ ì„¤ì •
    styles = getSampleStyleSheet()
    
    title_style = ParagraphStyle(
        'KoreanTitle',
        parent=styles['Title'],
        fontName=font_name,
        fontSize=22,
        spaceAfter=30,
        alignment=1  # ì¤‘ì•™ ì •ë ¬
    )
    
    heading_style = ParagraphStyle(
        'KoreanHeading',
        parent=styles['Heading2'],
        fontName=font_name,
        fontSize=15,
        spaceAfter=12,
        spaceBefore=18
    )
    
    normal_style = ParagraphStyle(
        'KoreanNormal',
        parent=styles['Normal'],
        fontName=font_name,
        fontSize=11,
        spaceAfter=10,
        leading=16
    )
    
    bullet_style = ParagraphStyle(
        'KoreanBullet',
        parent=styles['Normal'],
        fontName=font_name,
        fontSize=11,
        spaceAfter=8,
        leading=16,
        leftIndent=20
    )
    
    story = []
    
    # ì œëª©
    story.append(Paragraph("â¦¿ ë“œë¦¼ë¡œì§ ì§„ë¡œ íƒìƒ‰ ê²°ê³¼", title_style))
    story.append(Spacer(1, 20))
    
    # ìƒì„± ë‚ ì§œ
    current_date = datetime.now().strftime("%Yë…„ %mì›” %dì¼")
    story.append(Paragraph(f"ìƒì„±ì¼: {current_date}", normal_style))
    story.append(Spacer(1, 25))
    
    # ì§„ë¡œ íƒìƒ‰ ì„¹ì…˜ë“¤
    sections = [
        ("1ï¸âƒ£ ì„ íƒí•œ ì§ì—…", career_data.get('career', 'ì •ë³´ ì—†ìŒ')),
        ("2ï¸âƒ£ ì§ì—… ì„ íƒ ì´ìœ ", career_data.get('reasons', ['ì •ë³´ ì—†ìŒ'])),
        ("3ï¸âƒ£ ê´€ì‹¬ ìˆëŠ” ì´ìŠˆ", career_data.get('issues_selected', ['ì •ë³´ ì—†ìŒ'])),
        ("4ï¸âƒ£ íƒêµ¬ ì£¼ì œ", career_data.get('topic', 'ì •ë³´ ì—†ìŒ')),
        ("5ï¸âƒ£ ì§„ë¡œ ëª©í‘œ", career_data.get('goal', 'ì •ë³´ ì—†ìŒ')),
        ("6ï¸âƒ£ ì¤‘ê°„ ëª©í‘œ", career_data.get('midgoals', ['ì •ë³´ ì—†ìŒ'])),
    ]
    
    for section_title, section_content in sections:
        # ì„¹ì…˜ ì œëª©
        clean_title = clean_text_for_pdf(section_title)
        story.append(Paragraph(clean_title, heading_style))
        
        # ì„¹ì…˜ ë‚´ìš©
        if isinstance(section_content, list):
            for i, item in enumerate(section_content, 1):
                clean_item = clean_text_for_pdf(item)
                if len(section_content) > 1:
                    story.append(Paragraph(f"{i}. {clean_item}", bullet_style))
                else:
                    story.append(Paragraph(f"â€¢ {clean_item}", bullet_style))
        else:
            clean_content = clean_text_for_pdf(section_content)
            story.append(Paragraph(f"â€¢ {clean_content}", bullet_style))
        
        story.append(Spacer(1, 15))
    
    # ìµœì¢… ìš”ì•½
    final_summary = career_data.get('final_summary', '')
    if final_summary:
        story.append(Paragraph("7ï¸âƒ£ ìµœì¢… ì¢…í•© ê³„íš", heading_style))
        
        # ì¤„ë°”ê¿ˆìœ¼ë¡œ ë¶„ë¦¬í•˜ì—¬ ì²˜ë¦¬
        summary_lines = str(final_summary).split('\n')
        for line in summary_lines:
            line = line.strip()
            if line:
                clean_line = clean_text_for_pdf(line)
                story.append(Paragraph(clean_line, normal_style))
    
    # PDF ìƒì„±
    try:
        doc.build(story)
        print(f"âœ… PDF ìƒì„± ì™„ë£Œ: {temp_filename}")
        return temp_filename
    except Exception as e:
        print(f"âŒ PDF ìƒì„± ì˜¤ë¥˜: {e}")
        return None

