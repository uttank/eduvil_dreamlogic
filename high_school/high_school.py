# FastAPI ê¸°ë³¸ í˜•ì„ ì‘ì„±í•´ ì£¼ì„¸ìš”. ê°€ì¥ ê¸°ë³¸ì´ ë˜ëŠ” app ì™€ '/' url ì•  ëŒ€í•œ ì‚¬í•­ë§Œ ì ìš©í•¨
from fastapi import FastAPI, Request, Form
from fastapi.responses import HTMLResponse, RedirectResponse, FileResponse
from fastapi.templating import Jinja2Templates
from fastapi.staticfiles import StaticFiles
from typing import List, Optional
# openai ì˜ OpenAI APIë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ import
from openai import OpenAI
# python-dotenvë¥¼ ì‚¬ìš©í•˜ì—¬ í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
from dotenv import load_dotenv
import os
from datetime import datetime
import tempfile
# PDF ìƒì„±ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
from reportlab.lib.pagesizes import A4
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.lib.units import inch
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer
from reportlab.pdfbase import pdfmetrics
from reportlab.pdfbase.ttfonts import TTFont


# OpenAI API í‚¤ ì„¤ì •
load_dotenv()
_key = os.getenv("OPENAI_API_KEY")
#openai.api_key = _key
client = OpenAI(api_key=_key) # Or it will pick from environment variable

# ê¸°ë³¸ GPT ëª¨ë¸ ì„¤ì • (ëª¨ë¸ ì„ íƒ ê¸°ëŠ¥ ì œê±°)
DEFAULT_GPT_MODEL = "gpt-4.1-mini"
app = FastAPI()
templates_dir = os.path.join(os.path.dirname(__file__), "templates")
templates = Jinja2Templates(directory=templates_dir)
# ì •ì  íŒŒì¼(static) ê²½ë¡œ ë“±ë¡
import os
static_dir = os.path.join(os.path.dirname(__file__), "static")
app.mount("/static", StaticFiles(directory=static_dir), name="static")

@app.get("/")
async def index():
    return RedirectResponse(url="/high_school/career/flow")

# ì§„ë¡œ íƒìƒ‰ì„ ìœ„í•œ career ëª©ë¡ì„ ì €ì¥í•˜ê¸° ìœ„í•œ ë°ì´í„° êµ¬ì¡°
# ì§„ë¡œ íƒìƒ‰ 1ë‹¨ê³„ ì›í•˜ëŠ” ì§ì—…ì„ íƒ

# íŒŒì´ì¬ ë¦¬ìŠ¤íŠ¸ í˜•ì‹ì˜ ìë£Œêµ¬ì¡° ë¥¼ ì‚¬ìš©í•˜ì—¬ career ëª©ë¡ì„ ì €ì¥
# ì§„ë¡œ ê°€ì¹˜ íƒìƒ‰ 2ë‹¨ê³„ í”„ë¡¬í”„íŠ¸ì™€ ì„ íƒì§€ë¥¼ ë¦¬ìŠ¤íŠ¸ êµ¬ì¡°ë¡œ ì •ì˜
career_value_prompt = "2ë‹¨ê³„ ì™œ ì´ {career} ì„ í¬ë§í•˜ë‚˜ìš”? (ë³µìˆ˜ ì„ íƒ ê°€ëŠ¥)"
career_value_choices = [
    {"id": 1, "label": "ê²½ì œì  ê°€ì¹˜", "description": "ë†’ì€ ìˆ˜ì…, ì•ˆì •ì ì¸ ì§ì—…"},
    {"id": 2, "label": "ì‚¬íšŒì  ê°€ì¹˜", "description": "ì‚¬íšŒì— ê¸ì •ì ì¸ ì˜í–¥, ë´‰ì‚¬"},
    {"id": 3, "label": "ê³µë™ì²´ì  ê°€ì¹˜", "description": "ì‚¬ëŒë“¤ê³¼ í˜‘ë ¥, ì†Œí†µ"},
    {"id": 4, "label": "ëŠ¥ë ¥ ë°œíœ˜", "description": "ë‚˜ì˜ ì¬ëŠ¥ê³¼ ì—­ëŸ‰ì„ ìµœëŒ€í•œ ë°œíœ˜"},
    {"id": 5, "label": "ììœ¨Â·ì°½ì˜ì„±", "description": "ë…ë¦½ì ìœ¼ë¡œ ì¼í•˜ê³  ìƒˆë¡œìš´ ì•„ì´ë””ì–´ ì°½ì¶œ"},
    {"id": 6, "label": "ë¯¸ë˜ ë¹„ì „", "description": "ì„±ì¥ ê°€ëŠ¥ì„±, í˜ì‹ ì ì¸ ë¶„ì•¼"},
]

# ì§„ë¡œ ê°€ì¹˜ íƒìƒ‰ 3ë‹¨ê³„ í”„ë¡¬í”„íŠ¸ ì •ì˜ (ì„ íƒì§€ëŠ” ì˜ˆì‹œë¡œë§Œ ì£¼ì„ì— ëª…ì‹œ, ì‹¤ì œë¡œëŠ” ë§¤ë²ˆ ìƒì„±)
career_issue_prompt = (
    """
    3ë‹¨ê³„.
    ë‹¹ì‹ ì´ ì„ íƒí•œ '{career}' ì§ì—…ê³¼ ì„ íƒí•œ '{reasons}' ì´ìœ ì— ëŒ€í•´
    ê´€ë ¨ëœ ìµœì‹  ì´ìŠˆ ë˜ëŠ” í•´ê²° ê³¼ì œ ì¤‘ ê°€ì¥ ê´€ì‹¬ ìˆëŠ” ê²ƒì€ 5ê°€ì§€ ì œì‹œí•´ ì£¼ì„¸ìš”.
    # ì˜ˆì‹œ: ê¸°í›„ ìœ„ê¸°ì— ëŒ€ì‘í•˜ëŠ” ì§€ì† ê°€ëŠ¥í•œ ê±´ì¶• ê¸°ìˆ  ë¶€ì¡±, ê³ ë ¹í™” ì‚¬íšŒì˜ ëŒë´„ ì‹œìŠ¤í…œ ê°œì„ , ì¸ê³µì§€ëŠ¥ ìœ¤ë¦¬ ë¬¸ì œ í•´ê²°,
    # ë””ì§€í„¸ ê²©ì°¨ í•´ì†Œ ë°©ì•ˆ, ë¬¸í™” ì½˜í…ì¸ ì˜ ê¸€ë¡œë²Œ ê²½ìŸë ¥ ê°•í™”
    """
)
# ì‹¤ì œ ì„ íƒì§€ëŠ” OpenAI APIë¥¼ í†µí•´ careerì— ë”°ë¼ ë™ì ìœ¼ë¡œ ìƒì„±

# ì§„ë¡œ ê°€ì¹˜ íƒìƒ‰ 4ë‹¨ê³„ í”„ë¡¬í”„íŠ¸ ì •ì˜ (ì„ íƒì§€ëŠ” ì˜ˆì‹œë¡œë§Œ ì£¼ì„ì— ëª…ì‹œ, ì‹¤ì œë¡œëŠ” ë§¤ë²ˆ ìƒì„±)
career_topic_prompt = (
    """
    4ë‹¨ê³„.
    ì•ì„œ ì„ íƒí•œ '{career}' ì§ì—…ê³¼ '{reasons}' ì´ìœ ì— ëŒ€í•´ ê´€ë ¨ëœ ì´ìŠˆ ì¤‘ '{issue}' ì´ìŠˆì— ëŒ€í•´ 
    ì„ íƒëœ ë¬¸ì œì— ëŒ€í•´ êµ¬ì²´ì ìœ¼ë¡œ íƒêµ¬ ê°€ëŠ¥í•œ ì£¼ì œ 5ê°€ì§€ ì œì‹œí•´ì£¼ì„¸ìš”.
    # ê¸°ìˆ /ì •ì±…/ì‹¬ë¦¬/êµìœ¡/ë°ì´í„° ë¶„ì„ ë“± ë‹¤ì–‘í•œ ë°©ë²•ë¡  ì œì‹œ
    # ì¤‘ë³µ ì—†ì´ ìƒˆë¡œìš´ ì‹œì„  ê°•ì¡°
    """
)

# ì§„ë¡œ ê°€ì¹˜ íƒìƒ‰ 5ë‹¨ê³„ í”„ë¡¬í”„íŠ¸ ì •ì˜ (ì„ íƒì§€ëŠ” ì˜ˆì‹œë¡œë§Œ ì£¼ì„ì— ëª…ì‹œ, ì‹¤ì œë¡œëŠ” ë§¤ë²ˆ ìƒì„±)
career_goal_prompt = (
    """
    5ë‹¨ê³„.
    ì§€ê¸ˆê¹Œì§€ ì„ íƒí•œ ì§ì—…: '{career}', ì´ìœ : {reasons}, ì´ìŠˆ: '{issue}', íƒêµ¬ ì£¼ì œ: '{topic}'ë¥¼ ë°”íƒ•ìœ¼ë¡œ
    ì‚¬ìš©ìì—ê²Œ ì§„ë¡œ ëª©í‘œë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ ì œì‹œí•´ ì£¼ì„¸ìš”.
    {reasons} ì—ì„œ ì„ íƒí•œ ê°’ì„ ì°¸ê³ í•´ì„œ ê°€ì¹˜ê´€ì´ ì˜ ë“œëŸ¬ë‚˜ë„ë¡ êµ¬ì²´ì ìœ¼ë¡œ í‘œí˜„í•´ ì£¼ì„¸ìš”.
    # ì˜ˆì‹œ: 'ê¸°í›„ ìœ„ê¸° ëŒ€ì‘ì„ ìœ„í•œ ì¹œí™˜ê²½ ê±´ì¶• ì‹œìŠ¤í…œì„ ì„¤ê³„í•˜ì—¬ ì§€ì†ê°€ëŠ¥í•œ ë¯¸ë˜ ì£¼ê±° í˜•íƒœë¥¼ ì‹¤í˜„í•˜ëŠ” ê²ƒ
    """
)

# ì§„ë¡œ ê°€ì¹˜ íƒìƒ‰ 6ë‹¨ê³„ í”„ë¡¬í”„íŠ¸ ì •ì˜ (ì„ íƒì§€ëŠ” ì˜ˆì‹œë¡œë§Œ ì£¼ì„ì— ëª…ì‹œ, ì‹¤ì œë¡œëŠ” ë§¤ë²ˆ ìƒì„±)
career_midgoal_prompt = (
    """
    6ë‹¨ê³„.
    ì§€ê¸ˆê¹Œì§€ ì„ íƒí•œ ì§ì—…: '{career}', ì´ìœ : {reasons}, ì´ìŠˆ: '{issue}', íƒêµ¬ ì£¼ì œ: '{topic}', ìµœì¢… ëª©í‘œ: '{goal}'ì„(ë¥¼) ë°”íƒ•ìœ¼ë¡œ
    ìµœì¢… ëª©í‘œë¥¼ ì‹¤í˜„í•˜ê¸° ìœ„í•´ ê³ ë“±í•™ìƒ ìˆ˜ì¤€ì—ì„œ ê¸¸ëŸ¬ì•¼ í•  í•µì‹¬ ì—­ëŸ‰ ê¸°ë°˜ ì¤‘ê°„ ëª©í‘œ 3ê°œë¥¼ ì œì‹œí•´ ì£¼ì„¸ìš”
    
    [1] í•™ì—…ì—­ëŸ‰ì„ í¬í•¨í•˜ëŠ” ë‚´ìš©ìœ¼ë¡œ ì œì‹œ
    [2] ì§„ë¡œì—­ëŸ‰ë¥¼ í¬í•¨í•˜ëŠ” ë‚´ìš©ìœ¼ë¡œ ì œì‹œ
    [3] ê³µë™ì²´ì—­ëŸ‰ë¥¼ í¬í•¨í•˜ëŠ” ë‚´ìš©ìœ¼ë¡œ ì œì‹œ
    # ì˜ˆì‹œ: ì¹œí™˜ê²½ ê¸°ìˆ  ì—­ëŸ‰ ê°•í™” / ì„¤ê³„ ëŠ¥ë ¥ í–¥ìƒ / ê³µë™ì²´ì  ì‹¤ì²œì˜ì‹ í•¨ì–‘
    """
)

# ì§„ë¡œ ê°€ì¹˜ íƒìƒ‰ 7ë‹¨ê³„ í”„ë¡¬í”„íŠ¸ ì •ì˜ (ìµœì¢… í†µí•© ì •ë¦¬)
career_final_summary_prompt = (
    """
    7ë‹¨ê³„.
    ì§€ê¸ˆê¹Œì§€ ì„ íƒí•œ ì§ì—…: '{career}', ì´ìœ : {reasons}, ì´ìŠˆ: '{issue}', íƒêµ¬ ì£¼ì œ: '{topic}',
    ìµœì¢… ëª©í‘œ: '{goal}', ì¤‘ê°„ ëª©í‘œ: {midgoals}, ì„(ë¥¼) ë°”íƒ•ìœ¼ë¡œ ì•„ë˜ í˜•ì‹ìœ¼ë¡œ ëª¨ë“  ë‚´ìš©ì„ ëŒ€í•œë¯¼êµ­ ê³ ë“±í•™êµì—ì„œ ìˆ˜í–‰í•  ìˆ˜ ìˆëŠ” ìˆ˜ì¤€ì—ì„œ í†µí•©í•˜ì—¬ ì •ë¦¬í•´ ì£¼ì„¸ìš”.
    ìµœì¢…ëª©í‘œ, ì¤‘ê°„ëª©í‘œ, ì‹¤ì²œí™œë™ì—ë§Œ ì´ëª¨ì§€ë¥¼ ì‚¬ìš©í•´ì„œ ì‹œê°ì ìœ¼ë¡œ ë§¤ë ¥ì ì´ê³  ì½ê¸° ì‰½ê²Œ ë§Œë“¤ì–´ì£¼ì„¸ìš”.
    ì œí•œì¡°ê±´ì€ ê²°ê³¼ì— í‘œì‹œí•˜ì§€ ë§ê³  ë‚´ë¶€ì ìœ¼ë¡œë§Œ ì°¸ê³ í•˜ì„¸ìš”:
    ì•„ë˜ëŠ” ê±´ì¶•ê°€ë¥¼ í¬ë§í•˜ëŠ” ê³ ë“±í•™ìƒì˜ ì§„ë¡œ íƒìƒ‰ ê²°ê³¼ ì˜ˆì‹œì…ë‹ˆë‹¤.
    
    # ì˜ˆì‹œ:
        ğŸ¯ [ìµœì¢… ëª©í‘œ(ê¿ˆ)] ê¸°í›„ ìœ„ê¸° ëŒ€ì‘ì„ ìœ„í•œ ì¹œí™˜ê²½ ê±´ì¶• ì‹œìŠ¤í…œ ì„¤ê³„í•˜ì—¬ ì§€ì†ê°€ëŠ¥í•œ ë¯¸ë˜ ì£¼ê±° í˜•íƒœë¥¼ ì‹¤í˜„í•˜ëŠ” ê±´ì¶•ê°€

        ğŸ“š [ì¤‘ê°„ëª©í‘œ1] ì¹œí™˜ê²½ ê±´ì¶• ê¸°ìˆ  ì—­ëŸ‰
        ğŸ”¬ ì‹¤ì²œí™œë™1:
                    íƒêµ¬ë³´ê³ ì„œ: "ì œë¡œì—ë„ˆì§€ ê±´ì¶• ê¸°ìˆ ì˜ ì‹¤ì œ ì ìš© ì‚¬ë¡€ ë¶„ì„" ë“±
                    êµê³¼ í™œë™: ê³¼í•™ - 'ì—ë„ˆì§€ ì „í™˜' ë‹¨ì› [ì‹¬í™”]
                    ë¹„êµê³¼: ì—ë„ˆì§€ ì°½ì˜ ì„¤ê³„ ìº í”„ ì°¸ê°€ - [ë¬¸ì œ í•´ê²°ë ¥ ì„±ì¥ê³¼ ê´€ë ¨]
        ğŸ”¬ ì‹¤ì²œí™œë™2:
                    íƒêµ¬ë³´ê³ ì„œ:
                    êµê³¼ í™œë™: ê³¼í•™ - 'ìœ ì „ì í¸ì§‘ ê¸°ìˆ ' ë‹¨ì› [ì‹¬í™”]
                    ë¹„êµê³¼:
        ğŸ”¬ ì‹¤ì²œí™œë™3:
                    íƒêµ¬ë³´ê³ ì„œ:  
                    êµê³¼ í™œë™: ê³¼í•™ - ìœ ì „ìì™€~~
                    ë¹„êµê³¼:  
        
        ğŸ¨ [ì¤‘ê°„ëª©í‘œ2] ì„¤ê³„ ëŠ¥ë ¥ í–¥ìƒ
        ğŸ”¬ ì‹¤ì²œí™œë™1:
                    íƒêµ¬ë³´ê³ ì„œ: "ê±´ì¶• ì„¤ê³„ì˜ ê¸°ì´ˆì™€ ì‹¤ì œ" ë“±
                    êµê³¼ í™œë™: ê¸°íƒ€ - 'ê¸°ì´ˆ ì„¤ê³„ ì›ë¦¬'
                    ë¹„êµê³¼: ê±´ì¶• ì„¤ê³„ ì›Œí¬ìˆ ì°¸ê°€ - [ì°½ì˜ì  ë¬¸ì œ í•´ê²°ë ¥ ì„±ì¥ê³¼ ê´€ë ¨]
        ğŸ”¬ ì‹¤ì²œí™œë™2:
                    íƒêµ¬ë³´ê³ ì„œ: "ê±´ì¶• ì„¤ê³„ì˜ ê¸°ì´ˆì™€ ì‹¤ì œ" ë“±
                    êµê³¼ í™œë™: ê¸°íƒ€ - 'ê³ ê¸‰ ì„¤ê³„ ê¸°ë²•'
                    ë¹„êµê³¼: ê±´ì¶• ì„¤ê³„ ê²½ì§„ëŒ€íšŒ ì°¸ê°€ - [ì°½ì˜ì  ë¬¸ì œ í•´ê²°ë ¥ ì„±ì¥ê³¼ ê´€ë ¨]
        ğŸ”¬ ì‹¤ì²œí™œë™3:
                    íƒêµ¬ë³´ê³ ì„œ: "ê±´ì¶• ì„¤ê³„ì˜ ê¸°ì´ˆì™€ ì‹¤ì œ" ë“±
                    êµê³¼ í™œë™: ê¸°íƒ€ - 'ê±´ì¶• ì„¤ê³„ í”„ë¡œì íŠ¸'
                    ë¹„êµê³¼: ê±´ì¶• ì„¤ê³„ í”„ë¡œì íŠ¸ ë°œí‘œíšŒ ì°¸ê°€ - [ì°½ì˜ì  ë¬¸ì œ í•´ê²°ë ¥ ì„±ì¥ê³¼ ê´€ë ¨]
        
        ğŸ¤ [ì¤‘ê°„ëª©í‘œ3] ê³µë™ì²´ì  ì‹¤ì²œì˜ì‹ í•¨ì–‘
        ğŸ”¬ ì‹¤ì²œí™œë™1:
        
        ì œí•œ ì¡°ê±´ (ê²°ê³¼ì— í‘œì‹œí•˜ì§€ ë§ê³  ë‚´ë¶€ì ìœ¼ë¡œë§Œ ì°¸ê³ ):
        0. í•™ë…„ë³„ êµê³¼ í™œë™ì˜ ê²½ìš° ì•„ë˜ í‘œì‹œí•œ'2022 êµìœ¡ê°œí¸ì¤‘ ê³ ë“±í•™êµ êµìœ¡ê³¼ì •' ë°˜ì˜í•˜ì—¬ í™œë™ ì œì‹œ
            ì œí•œ ì¡°ê±´ (ê²°ê³¼ì— í‘œì‹œí•˜ì§€ ë§ê³  ë‚´ë¶€ì ìœ¼ë¡œë§Œ ì°¸ê³ ):
        1. êµê³¼ í™œë™ì€ ë°˜ë“œì‹œ 2022 ê°œì • êµìœ¡ê³¼ì •ì˜ ì •í™•í•œ êµê³¼ëª©ëª…ë§Œ ì‚¬ìš©:
            ì•„ë˜ í˜•ì‹ì€ **ì˜ì—­**:ê³¼ëª©ëª….. ìœ¼ë¡œ í‘œì‹œ
            **êµ­ì–´**: ê³µí†µêµ­ì–´, í™”ë²•ê³¼ ì–¸ì–´, ë…ì„œì™€ ì‘ë¬¸, ë¬¸í•™, ì£¼ì œ íƒêµ¬ ë…ì„œ, ë¬¸í•™ê³¼ ì˜ìƒ, ì§ë¬´ ì˜ì‚¬ì†Œí†µ, ë…ì„œ í† ë¡ ê³¼ ê¸€ì“°ê¸°, ë§¤ì²´ ì˜ì‚¬ì†Œí†µ, ì–¸ì–´ìƒí™œ íƒêµ¬
            **ìˆ˜í•™**: ê³µí†µìˆ˜í•™, ëŒ€ìˆ˜, ë¯¸ì ë¶„, í™•ë¥ ê³¼ í†µê³„, ê¸°í•˜, ê²½ì œ ìˆ˜í•™, ì¸ê³µì§€ëŠ¥ ìˆ˜í•™, ì§ë¬´ìˆ˜í•™, ìˆ˜í•™ê³¼ ë¬¸í™”, ì‹¤ìš©í†µê³„, ìˆ˜í•™ê³¼ì œ íƒêµ¬
            **ì˜ì–´**: ê³µí†µì˜ì–´, ì˜ì–´ ë…í•´ì™€ ì‘ë¬¸, ì˜ë¯¸ ë¬¸í•™ ì½ê¸°, ì˜ì–´ ë°œí‘œì™€ í† ë¡ , ì‹¬í™” ì˜ì–´, ì§ë¬´ ì˜ì–´, ì‹¤ìƒí™œ ì˜ì–´íšŒí™”, ë¯¸ë””ì–´ ì˜ì–´, ì„¸ê³„ ë¬¸í™”ì™€ ì˜ì–´
            **ì‚¬íšŒ**: í•œêµ­ì‚¬, í†µí•©ì‚¬íšŒ, ì„¸ê³„ì‹œë¯¼ê³¼ ì§€ë¦¬, ì„¸ê³„ì‚¬, ì‚¬íšŒì™€ ë¬¸í™”, í˜„ëŒ€ì‚¬íšŒì™€ ìœ¤ë¦¬, í•œêµ­ì§€ë¦¬ íƒêµ¬, ë„ì‹œì˜ ë¯¸ë˜ íƒêµ¬, ë™ì•„ì‹œì•„ ì—­ì‚¬ ê¸°í–‰, ì •ì¹˜, ë²•ê³¼ ì‚¬íšŒ, ê²½ì œ, ì‚¬íšŒ ë¬¸ì œ íƒêµ¬, ìœ¤ë¦¬ì™€ ì‚¬ìƒ, ì¸ë¬¸í•™ê³¼ ìœ¤ë¦¬, êµ­ì œ ê´€ê³„ì˜ ì´í•´, ì—¬í–‰ì§€ë¦¬, ì—­ì‚¬ë¥¼ íƒêµ¬í•˜ëŠ” í˜„ëŒ€ ì„¸ê³„, ê¸ˆìœµê³¼ ê²½ì œìƒí™œ, ìœ¤ë¦¬ë¬¸ì œ íƒêµ¬, ê¸°í›„ë³€í™”ì™€ ì§€ì†ê°€ëŠ¥í•œ ì„¸ê³„
            **ê³¼í•™**: í†µí•©ê³¼í•™, ê³¼í•™íƒêµ¬ì‹¤í—˜, ë¬¼ë¦¬í•™, í™”í•™, ìƒëª…ê³¼í•™, ì§€êµ¬ê³¼í•™, ì—­í•™ê³¼ ì—ë„ˆì§€, ì „ìê¸°ì™€ ì–‘ì, ë¬¼ì§ˆê³¼ ì—ë„ˆì§€, í™”í•™ë°˜ì‘ì˜ ì„¸ê³„, ì„¸í¬ì™€ ë¬¼ì§ˆëŒ€ì‚¬, ìƒë¬¼ì˜ ìœ ì „, ì§€êµ¬ ì‹œìŠ¤í…œê³¼í•™, í–‰ì„±ìš°ì£¼ê³¼í•™, ê³¼í•™ì˜ ì—­ì‚¬ì™€ ë¬¸í™”, ê¸°í›„ë³€í™”ì™€ í™˜ê²½ìƒíƒœ, ìœµí•©ê³¼í•™ íƒêµ¬
            **ê¸°íƒ€**: ê¸°ìˆ ê°€ì •, ì •ë³´, ë¡œë´‡ê³¼ ê³µí•™ì„¸ê³„, ìƒí™œê³¼í•™ íƒêµ¬, ì¸ê³µì§€ëŠ¥ ê¸°ì´ˆ, ë°ì´í„° ê³¼í•™, ì°½ì˜ ê³µí•™ ì„¤ê³„, ì§€ì‹ ì¬ì‚° ì¼ë°˜, ìƒì• ì„¤ê³„ì™€ ìë¦½, ì²´ìœ¡, ì˜ˆìˆ 
        2. í•™êµì™¸ì— ëŒ€íšŒë‚˜ ê³µëª¨ì „ì€ ì–¸ê¸‰í•˜ì§€ ì•Šê¸°. í•™êµì—ì„œ ì´ë£¨ì–´ì§ˆ ìˆ˜ ìˆëŠ” í™œë™ìœ¼ë¡œë§Œ ì‹¤ì²œí™œë™ ì œì‹œí•˜ê¸°
        3. ìì†Œì„œ ë“±ì€ ì–¸ê¸‰í•˜ì§€ ì•Šê¸°
        4. ê³ ë“±í•™ìƒ ìˆ˜ì¤€ì—ì„œ ì´í•´ í•  ìˆ˜ ìˆëŠ” íƒêµ¬í™œë™ ì£¼ì œ ì œì‹œ
            "ê° í•­ëª©ì€ ì‹¤ì œ ì…ë ¥ê°’ì— ë§ê²Œ êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”."
    """
)



@app.get("/career/flow", response_class=HTMLResponse)
async def career_flow_get(request: Request):
    now = datetime.now().timestamp()
    return templates.TemplateResponse("career_flow_allinone.html", {
        "request": request, 
        "step": 1, 
        "start_time": now, 
        "step_start_time": now
    })

@app.post("/career/flow", response_class=HTMLResponse)
async def career_flow_post(
    request: Request,
    step: int = Form(1),
    career: Optional[str] = Form(None),
    reasons: Optional[List[str]] = Form(None),
    issue: Optional[str] = Form(None),
    topic: Optional[str] = Form(None),
    goal: Optional[str] = Form(None),
    midgoals: Optional[List[str]] = Form(None),
    midgoal_details: Optional[str] = Form(None),
    practices: Optional[str] = Form(None),
    start_time: Optional[float] = Form(None),
    step_start_time: Optional[float] = Form(None),
):
    now = datetime.now().timestamp()
    context = {"request": request, "step": step}
    
    # start_time ê´€ë¦¬
    if not start_time:
        start_time = now
    context["start_time"] = start_time
    # step_start_time ê´€ë¦¬ (ë‹¨ê³„ë³„ ì†Œìš” ì‹œê°„ ì‚­ì œ, current_step_timeë„ ì‚­ì œ)
    if not step_start_time:
        step_start_time = now
    context["step_start_time"] = step_start_time
    chatbot_message = None
    # 1ë‹¨ê³„: ì§ì—… ì…ë ¥
    if step == 1:
        if not career:
            context.update({"error": "ì§ì—…ì„ ì…ë ¥í•˜ì„¸ìš”."})
            return templates.TemplateResponse("career_flow_allinone.html", context)
        choices = career_value_choices
        chatbot_message = f"'{career}'(ì„)ë¥¼ ì„ íƒí•˜ì…¨êµ°ìš”. ì´ ì§ì—…ì„ ì„ íƒí•œ ì´ìœ ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”!"
        context.update({
            "step": 2, 
            "career": career, 
            "choices": choices, 
            "chatbot_message": chatbot_message
        })
        return templates.TemplateResponse("career_flow_allinone.html", context)
    # 2ë‹¨ê³„: ì´ìœ  ë³µìˆ˜ ì„ íƒ
    elif step == 2:
        if not (career and reasons):
            context.update({
                "step": 2, 
                "career": career, 
                "choices": career_value_choices, 
                "error": "ì´ìœ ë¥¼ í•œ ê°€ì§€ ì´ìƒ ì„ íƒí•˜ì„¸ìš”."
            })
            return templates.TemplateResponse("career_flow_allinone.html", context)
        chatbot_message = f"{', '.join(reasons)}(ì„)ë¥¼ ì„ íƒí•˜ì…¨êµ°ìš”. ì´ì œ {career}ì™€ ê´€ë ¨ëœ ìµœì‹  ì´ìŠˆë¥¼ ê³¨ë¼ë³¼ê¹Œìš”?"
        # 3ë‹¨ê³„ë¡œ ì´ë™ (OpenAI APIë¡œ ì´ìŠˆ ìƒì„±)
        issues = call_gpt_list(
            prompt=career_issue_prompt.format(career=career, reasons=', '.join(reasons) if reasons else ''),
            system_message="ë„ˆëŠ” ì§„ë¡œ íƒìƒ‰ì„ ë•ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ì•¼. ì‚¬ìš©ìê°€ ì„ íƒí•œ ì§ì—…ê³¼ ê´€ë ¨ëœ ìµœì‹  ì´ìŠˆë‚˜ í•´ê²° ê³¼ì œ 5ê°€ì§€ë¥¼ í•œêµ­ì–´ë¡œ ê°„ê²°í•˜ê²Œ ì œì‹œí•´ì¤˜.",
            
            max_completion_tokens=3000,
            fallback=["ì´ìŠˆë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."],
            strip_chars='-â€¢ '
        )
        context.update({
            "step": 3, 
            "career": career, 
            "reasons": reasons, 
            "issues": issues, 
            "chatbot_message": chatbot_message,
            
        })
        return templates.TemplateResponse("career_flow_allinone.html", context)
    # 3ë‹¨ê³„: ì´ìŠˆ ì„ íƒ
    elif step == 3:
        form = await request.form()
        regenerate = form.get("regenerate")
        # ë‹¤ì¤‘ ì„ íƒ ì§€ì›: issuesëŠ” ë¦¬ìŠ¤íŠ¸
        issues_selected = [str(x) for x in form.getlist("issues")]
        # 'ë‹¤ì‹œ ìƒì„±' ë²„íŠ¼ ì²˜ë¦¬
        if regenerate == "yes":
            # ê¸°ì¡´ ì´ìŠˆë“¤ì„ í¼ì—ì„œ ë°›ì•„ì˜´ (í˜„ì¬ í˜ì´ì§€ì— í‘œì‹œëœ ì´ìŠˆë“¤)
            current_issues = form.getlist("current_issues") or []
            existing_issues_text = "\\n".join([f"- {issue}" for issue in current_issues]) if current_issues else ""
            
            # ìƒˆë¡œìš´ í”„ë¡¬í”„íŠ¸ë¡œ ê¸°ì¡´ ì´ìŠˆì™€ ë‹¤ë¥¸ ì´ìŠˆ ìƒì„±
            regenerate_prompt = f"""
            3ë‹¨ê³„ - ìƒˆë¡œìš´ ì´ìŠˆ ìƒì„±.
            ë‹¹ì‹ ì´ ì„ íƒí•œ '{career}' ì§ì—…ê³¼ ì„ íƒí•œ '{', '.join(reasons) if reasons else ''}' ì´ìœ ì— ëŒ€í•´
            ê´€ë ¨ëœ ìµœì‹  ì´ìŠˆ ë˜ëŠ” í•´ê²° ê³¼ì œ ì¤‘ ê°€ì¥ ê´€ì‹¬ ìˆëŠ” ê²ƒì„ 5ê°€ì§€ ì œì‹œí•´ ì£¼ì„¸ìš”.
            
            **ì¤‘ìš”**: ì•„ë˜ ê¸°ì¡´ì— ì œì‹œëœ ì´ìŠˆë“¤ê³¼ëŠ” ì™„ì „íˆ ë‹¤ë¥¸ ìƒˆë¡œìš´ ê´€ì ì˜ ì´ìŠˆë¥¼ ì œì‹œí•´ì£¼ì„¸ìš”:
            {existing_issues_text}
           """
            
            issues = call_gpt_list(
                prompt=regenerate_prompt,
                system_message="ë„ˆëŠ” ì§„ë¡œ íƒìƒ‰ì„ ë•ëŠ” ì°½ì˜ì ì¸ ì–´ì‹œìŠ¤í„´íŠ¸ì•¼. ê¸°ì¡´ê³¼ëŠ” ì™„ì „íˆ ë‹¤ë¥¸ ìƒˆë¡œìš´ ê´€ì ì˜ ì´ìŠˆ 5ê°€ì§€ë¥¼ í•œêµ­ì–´ë¡œ ê°„ê²°í•˜ê²Œ ì œì‹œí•´ì¤˜. ê¸°ì¡´ ì´ìŠˆì™€ ìœ ì‚¬í•˜ê±°ë‚˜ ì¤‘ë³µë˜ëŠ” ë‚´ìš©ì€ ì ˆëŒ€ í”¼í•´ì¤˜.",
                max_completion_tokens=3000,
                temperature=0.3,  # ë†’ì€ ì°½ì˜ì„±ì„ ìœ„í•´
                fallback=["ì´ìŠˆë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."],
                strip_chars='-â€¢ '
            )
            chatbot_message = f"ì´ìŠˆë¥¼ ìƒˆë¡œ ì œì•ˆí•©ë‹ˆë‹¤. ì›í•˜ëŠ” ì´ìŠˆë¥¼ ëª¨ë‘ ì„ íƒí•˜ì„¸ìš”."
            context.update({
                "step": 3, 
                "career": career, 
                "reasons": reasons, 
                "issues": issues, 
                "chatbot_message": chatbot_message, 
                "issues_selected": [],
                
            })
            return templates.TemplateResponse("career_flow_allinone.html", context)
        if not (career and reasons and issues_selected):
            context.update({
                "step": 3, 
                "career": career, 
                "reasons": reasons, 
                "issues": context.get("issues", []), 
                "error": "ì´ìŠˆë¥¼ í•œ ê°€ì§€ ì´ìƒ ì„ íƒí•˜ì„¸ìš”.", 
                "issues_selected": issues_selected,
                
            })
            return templates.TemplateResponse("career_flow_allinone.html", context)
        chatbot_message = f"{', '.join(issues_selected)}(ì„)ë¥¼ ì„ íƒí•˜ì…¨êµ°ìš”. ì´ ì´ìŠˆë“¤ì— ëŒ€í•´ íƒêµ¬í•˜ê³  ì‹¶ì€ ì£¼ì œë¥¼ ê³¨ë¼ì£¼ì„¸ìš”!"
        # 4ë‹¨ê³„ë¡œ ì´ë™ (OpenAI APIë¡œ íƒêµ¬ ì£¼ì œ ìƒì„±, ì²« ë²ˆì§¸ ì´ìŠˆë§Œ ì‚¬ìš©)
        topics = call_gpt_list(
            prompt=career_topic_prompt.format(career=career, reasons=', '.join(reasons) if reasons else '', issue=issues_selected[0]),
            system_message="ë„ˆëŠ” ì§„ë¡œ íƒìƒ‰ì„ ë•ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ì•¼. ì‚¬ìš©ìê°€ ì„ íƒí•œ ì´ìŠˆì— ëŒ€í•´ êµ¬ì²´ì ìœ¼ë¡œ íƒêµ¬ ê°€ëŠ¥í•œ ì£¼ì œ 5ê°€ì§€ë¥¼ í•œêµ­ì–´ë¡œ ê°„ê²°í•˜ê²Œ ì œì‹œí•´ì¤˜.",
            
            max_completion_tokens=2500,
            fallback=["ì£¼ì œë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."],
            strip_chars='-â€¢[]1234567890. '
        )
        context.update({
            "step": 4, 
            "career": career, 
            "reasons": reasons, 
            "issues_selected": issues_selected, 
            "topics": topics, 
            "chatbot_message": chatbot_message,
            
        })
        return templates.TemplateResponse("career_flow_allinone.html", context)
    # 4ë‹¨ê³„: íƒêµ¬ ì£¼ì œ ì„ íƒ
    elif step == 4:
        form = await request.form()
        regenerate = form.get("regenerate")
        topic = form.get("topic") # type: ignore
        # issues_selectedë¥¼ hidden inputì—ì„œ ë°›ì•„ì˜´
        issues_selected = form.getlist("issues_selected")
        
        # 'ë‹¤ì‹œ ìƒì„±' ë²„íŠ¼ ì²˜ë¦¬
        if regenerate == "yes":
            # ê¸°ì¡´ ì£¼ì œë“¤ì„ í¼ì—ì„œ ë°›ì•„ì˜´
            current_topics = form.getlist("current_topics") or []
            existing_topics_text = "\\n".join([f"- {topic}" for topic in current_topics]) if current_topics else ""
            
            # ìƒˆë¡œìš´ í”„ë¡¬í”„íŠ¸ë¡œ ê¸°ì¡´ ì£¼ì œì™€ ë‹¤ë¥¸ ì£¼ì œ ìƒì„±
            regenerate_prompt = f"""
            4ë‹¨ê³„ - ìƒˆë¡œìš´ íƒêµ¬ ì£¼ì œ ìƒì„±.
            ì•ì„œ ì„ íƒí•œ '{career}' ì§ì—…ê³¼ '{', '.join(reasons) if reasons else ''}' ì´ìœ ì— ëŒ€í•´ ê´€ë ¨ëœ ì´ìŠˆ ì¤‘ '{issues_selected[0]}' ì´ìŠˆì— ëŒ€í•´ 
            ì„ íƒëœ ë¬¸ì œì— ëŒ€í•´ êµ¬ì²´ì ìœ¼ë¡œ íƒêµ¬ ê°€ëŠ¥í•œ ì£¼ì œë¥¼ 5ê°€ì§€ ì œì‹œí•´ì£¼ì„¸ìš”.
            
            **ì¤‘ìš”**: ì•„ë˜ ê¸°ì¡´ì— ì œì‹œëœ ì£¼ì œë“¤ê³¼ëŠ” ì™„ì „íˆ ë‹¤ë¥¸ ìƒˆë¡œìš´ ì ‘ê·¼ë²•ì˜ ì£¼ì œë¥¼ ì œì‹œí•´ì£¼ì„¸ìš”:
            {existing_topics_text}
            """
            
            topics = call_gpt_list(
                prompt=regenerate_prompt,
                system_message="ë„ˆëŠ” ì§„ë¡œ íƒìƒ‰ì„ ë•ëŠ” ì°½ì˜ì ì¸ ì–´ì‹œìŠ¤í„´íŠ¸ì•¼. ê¸°ì¡´ê³¼ëŠ” ì™„ì „íˆ ë‹¤ë¥¸ ìƒˆë¡œìš´ ë°©ë²•ë¡ ì˜ íƒêµ¬ ì£¼ì œ 5ê°€ì§€ë¥¼ í•œêµ­ì–´ë¡œ ê°„ê²°í•˜ê²Œ ì œì‹œí•´ì¤˜. ê¸°ì¡´ ì£¼ì œì™€ ìœ ì‚¬í•˜ê±°ë‚˜ ì¤‘ë³µë˜ëŠ” ë‚´ìš©ì€ ì ˆëŒ€ í”¼í•´ì¤˜.",
                max_completion_tokens=2500,
                temperature=0.3,  # ë†’ì€ ì°½ì˜ì„±ì„ ìœ„í•´
                fallback=["ì£¼ì œë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."],
                strip_chars='-â€¢[]1234567890. '
            )
            chatbot_message = f"ì£¼ì œë¥¼ ìƒˆë¡œ ì œì•ˆí•©ë‹ˆë‹¤. ì›í•˜ëŠ” ì£¼ì œë¥¼ ì„ íƒí•˜ì„¸ìš”."
            context.update({
                "step": 4, 
                "career": career, 
                "reasons": reasons, 
                "issues_selected": issues_selected, 
                "topics": topics, 
                "chatbot_message": chatbot_message,
                
            })
            return templates.TemplateResponse("career_flow_allinone.html", context)
        
        # ì£¼ì œ ì„ íƒ ê²€ì¦ (ì¬ìƒì„±ì´ ì•„ë‹Œ ê²½ìš°ì—ë§Œ)
        if not (career and reasons and issues_selected):
            # ê¸°ë³¸ topics ìƒì„±í•´ì„œ ì—ëŸ¬ ìƒí™©ì—ì„œë„ í‘œì‹œ
            topics = call_gpt_list(
                prompt=career_topic_prompt.format(career=career, reasons=', '.join(reasons) if reasons else '', issue=issues_selected[0] if issues_selected else "ì¼ë°˜ì ì¸ ì£¼ì œ"),
                system_message="ë„ˆëŠ” ì§„ë¡œ íƒìƒ‰ì„ ë•ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ì•¼. ì‚¬ìš©ìê°€ ì„ íƒí•œ ì´ìŠˆì— ëŒ€í•´ êµ¬ì²´ì ìœ¼ë¡œ íƒêµ¬ ê°€ëŠ¥í•œ ì£¼ì œ 5ê°€ì§€ë¥¼ í•œêµ­ì–´ë¡œ ê°„ê²°í•˜ê²Œ ì œì‹œí•´ì¤˜.",
                
                max_completion_tokens=2500,
                fallback=["ì£¼ì œë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."],
                strip_chars='-â€¢[]1234567890. '
            )
            context.update({
                "step": 4, 
                "career": career, 
                "reasons": reasons, 
                "issues_selected": issues_selected, 
                "topics": topics, 
                "error": "ì´ì „ ë‹¨ê³„ ì •ë³´ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.",
                
            })
            return templates.TemplateResponse("career_flow_allinone.html", context)
        
        if not topic:
            # ì£¼ì œê°€ ì„ íƒë˜ì§€ ì•Šì€ ê²½ìš°, ê¸°ë³¸ topics ìƒì„±
            topics = call_gpt_list(
                prompt=career_topic_prompt.format(career=career, reasons=', '.join(reasons) if reasons else '', issue=issues_selected[0]),
                system_message="ë„ˆëŠ” ì§„ë¡œ íƒìƒ‰ì„ ë•ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ì•¼. ì‚¬ìš©ìê°€ ì„ íƒí•œ ì´ìŠˆì— ëŒ€í•´ êµ¬ì²´ì ìœ¼ë¡œ íƒêµ¬ ê°€ëŠ¥í•œ ì£¼ì œ 5ê°€ì§€ë¥¼ í•œêµ­ì–´ë¡œ ê°„ê²°í•˜ê²Œ ì œì‹œí•´ì¤˜.",
                
                max_completion_tokens=2500,
                fallback=["ì£¼ì œë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."],
                strip_chars='-â€¢[]1234567890. '
            )
            context.update({
                "step": 4, 
                "career": career, 
                "reasons": reasons, 
                "issues_selected": issues_selected, 
                "topics": topics, 
                "error": "ì£¼ì œë¥¼ ì„ íƒí•˜ì„¸ìš”.",
                
            })
            return templates.TemplateResponse("career_flow_allinone.html", context)
        # 5ë‹¨ê³„: GPTê°€ ì œì‹œí•˜ëŠ” ì§„ë¡œ ëª©í‘œ
        suggested_goal_list = call_gpt_list(
            prompt=career_goal_prompt.format(career=career, reasons=reasons, issue=issues_selected[0], topic=topic),
            system_message="ë„ˆëŠ” ì§„ë¡œ íƒìƒ‰ì„ ë•ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ì•¼. ì‚¬ìš©ìì˜ ì„ íƒì„ ë°”íƒ•ìœ¼ë¡œ ì ì ˆí•œ ì§„ë¡œ ëª©í‘œë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ ì œì‹œí•´ì¤˜.",
            
            max_completion_tokens=1000,
            fallback=["ì§„ë¡œ ëª©í‘œë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."],
            strip_chars=''  # í•œ ë¬¸ì¥ë§Œ ë°˜í™˜
        )
        suggested_goal = suggested_goal_list[0] if suggested_goal_list else "ì§„ë¡œ ëª©í‘œë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
        chatbot_message = f"ì•„ë˜ì™€ ê°™ì€ ì§„ë¡œ ëª©í‘œë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ë§ˆìŒì— ë“¤ì§€ ì•Šìœ¼ë©´ 'ë‹¤ì‹œ ìƒì„±'ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”."
        context.update({
            "step": 5, 
            "career": career, 
            "reasons": reasons, 
            "issues_selected": issues_selected, 
            "topic": topic, 
            "suggested_goal": suggested_goal, 
            "chatbot_message": chatbot_message,
            
        })
        return templates.TemplateResponse("career_flow_allinone.html", context)
    # 5ë‹¨ê³„: ì§„ë¡œ ëª©í‘œ í™•ì¸ ë° ì¬ìƒì„±
    elif step == 5:
        form = await request.form()
        suggested_goal = form.get("suggested_goal")
        regenerate = form.get("regenerate")
        issues_selected = form.getlist("issues_selected")
        if regenerate == "yes":
            # ê¸°ì¡´ ëª©í‘œë¥¼ í¼ì—ì„œ ë°›ì•„ì˜´
            current_goal = form.get("current_goal") or suggested_goal or ""
            
            # ìƒˆë¡œìš´ í”„ë¡¬í”„íŠ¸ë¡œ ê¸°ì¡´ ëª©í‘œì™€ ë‹¤ë¥¸ ëª©í‘œ ìƒì„±
            regenerate_prompt = f"""
            5ë‹¨ê³„ - ìƒˆë¡œìš´ ì§„ë¡œ ëª©í‘œ ìƒì„±.
            ì§€ê¸ˆê¹Œì§€ ì„ íƒí•œ ì§ì—…: '{career}', ì´ìœ : {reasons}, ì´ìŠˆ: '{issues_selected[0]}', íƒêµ¬ ì£¼ì œ: '{topic}'ë¥¼ ë°”íƒ•ìœ¼ë¡œ
            ì‚¬ìš©ìì—ê²Œ ì§„ë¡œ ëª©í‘œë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ ì œì‹œí•´ ì£¼ì„¸ìš”.
            {reasons} ì—ì„œ ì„ íƒí•œ ê°’ì„ ì°¸ê³ í•´ì„œ ê°€ì¹˜ê´€ì´ ì˜ ë“œëŸ¬ë‚˜ë„ë¡ êµ¬ì²´ì ìœ¼ë¡œ í‘œí˜„í•´ ì£¼ì„¸ìš”.
            
            **ì¤‘ìš”**: ì•„ë˜ ê¸°ì¡´ì— ì œì‹œëœ ëª©í‘œì™€ëŠ” ì™„ì „íˆ ë‹¤ë¥¸ ìƒˆë¡œìš´ ê´€ì ì˜ ëª©í‘œë¥¼ ì œì‹œí•´ì£¼ì„¸ìš”:
            ê¸°ì¡´ ëª©í‘œ: {current_goal}
            """
            
            # ëª©í‘œ ì¬ìƒì„±
            suggested_goal_list = call_gpt_list(
                prompt=regenerate_prompt,
                system_message="ë„ˆëŠ” ì§„ë¡œ íƒìƒ‰ì„ ë•ëŠ” ì°½ì˜ì ì¸ ì–´ì‹œìŠ¤í„´íŠ¸ì•¼. ê¸°ì¡´ê³¼ëŠ” ì™„ì „íˆ ë‹¤ë¥¸ ìƒˆë¡œìš´ ê´€ì ì˜ ì§„ë¡œ ëª©í‘œë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ ì œì‹œí•´ì¤˜. ê¸°ì¡´ ëª©í‘œì™€ ìœ ì‚¬í•˜ê±°ë‚˜ ì¤‘ë³µë˜ëŠ” ë‚´ìš©ì€ ì ˆëŒ€ í”¼í•´ì¤˜.",
                max_completion_tokens=1000,
                temperature=0.3,
                fallback=["ì§„ë¡œ ëª©í‘œë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."],
                strip_chars=''
            )
            suggested_goal = suggested_goal_list[0] if suggested_goal_list else "ì§„ë¡œ ëª©í‘œë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
            chatbot_message = "ì•„ë˜ì™€ ê°™ì´ ìƒˆë¡­ê²Œ ì§„ë¡œ ëª©í‘œë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ë§ˆìŒì— ë“¤ì§€ ì•Šìœ¼ë©´ ë‹¤ì‹œ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            context.update({
                "step": 5, 
                "career": career, 
                "reasons": reasons, 
                "issues_selected": issues_selected, 
                "topic": topic, 
                "suggested_goal": suggested_goal, 
                "chatbot_message": chatbot_message,
                
            })
            return templates.TemplateResponse("career_flow_allinone.html", context)
        # ì‚¬ìš©ìê°€ ëª©í‘œë¥¼ ìˆ˜ë½
        goal = str(suggested_goal) if suggested_goal is not None else None
        chatbot_message = f"'{goal}'(ì„)ë¥¼ ëª©í‘œë¡œ í•˜ì…¨êµ°ìš”. ì´ì œ ì¤‘ê°„ ëª©í‘œ 5ê°€ì§€ë¥¼ ì œì‹œí•´ë“œë¦´ê²Œìš”."
        # 6ë‹¨ê³„ë¡œ ì´ë™ (OpenAI APIë¡œ ì¤‘ê°„ ëª©í‘œ ìƒì„±)
        midgoals = call_gpt_list(
            prompt=career_midgoal_prompt.format(career=career, reasons=reasons, issue=issues_selected[0], topic=topic, goal=goal),
            system_message="ë„ˆëŠ” ì§„ë¡œ íƒìƒ‰ì„ ë•ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ì•¼. ì‚¬ìš©ìì˜ ìµœì¢… ëª©í‘œë¥¼ ì‹¤í˜„í•˜ê¸° ìœ„í•œ ì¤‘ê°„ ëª©í‘œ 5ê°€ì§€ë¥¼ í•œêµ­ì–´ë¡œ ê°„ê²°í•˜ê²Œ ì œì‹œí•´ì¤˜.",
            
            max_completion_tokens=3000,
            fallback=["ì¤‘ê°„ ëª©í‘œë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."],
            strip_chars='-â€¢[]1234567890. '
        )
        context.update({
            "step": 6, 
            "career": career, 
            "reasons": reasons, 
            "issues_selected": issues_selected, 
            "topic": topic, 
            "goal": goal, 
            "midgoals": midgoals, 
            "chatbot_message": chatbot_message,
            
        })
        return templates.TemplateResponse("career_flow_allinone.html", context)
    # 6ë‹¨ê³„: ì¤‘ê°„ ëª©í‘œ ì œì‹œ ë° ì¬ìƒì„± (ì„ íƒ ì•„ë‹˜, ì œì‹œë§Œ)
    elif step == 6:
        form = await request.form()
        regenerate = form.get("regenerate")
        issues_selected = form.getlist("issues_selected")
        # ì¬ìƒì„± ìš”ì²­ ì‹œ midgoals ìƒˆë¡œ ìƒì„±
        if regenerate == "yes":
            # ê¸°ì¡´ ì¤‘ê°„ ëª©í‘œë“¤ì„ í¼ì—ì„œ ë°›ì•„ì˜´
            current_midgoals = form.getlist("current_midgoals") or midgoals or []
            existing_midgoals_text = "\\n".join([f"- {mg}" for mg in current_midgoals]) if current_midgoals else ""
            
            # ìƒˆë¡œìš´ í”„ë¡¬í”„íŠ¸ë¡œ ê¸°ì¡´ ì¤‘ê°„ ëª©í‘œì™€ ë‹¤ë¥¸ ëª©í‘œ ìƒì„±
            regenerate_prompt = f"""
            6ë‹¨ê³„ - ìƒˆë¡œìš´ ì¤‘ê°„ ëª©í‘œ ìƒì„±.
            ì§€ê¸ˆê¹Œì§€ ì„ íƒí•œ ì§ì—…: '{career}', ì´ìœ : {reasons}, ì´ìŠˆ: '{issues_selected[0]}', íƒêµ¬ ì£¼ì œ: '{topic}', ìµœì¢… ëª©í‘œ: '{goal}'ì„(ë¥¼) ë°”íƒ•ìœ¼ë¡œ
            ìµœì¢… ëª©í‘œë¥¼ ì‹¤í˜„í•˜ê¸° ìœ„í•´ ê³ ë“±í•™ìƒ ìˆ˜ì¤€ì—ì„œ ê¸¸ëŸ¬ì•¼ í•  í•µì‹¬ ì—­ëŸ‰ ê¸°ë°˜ ì¤‘ê°„ ëª©í‘œ 3ê°œë¥¼ ì œì‹œí•´ ì£¼ì„¸ìš”
            
            [1] í•™ì—…ì—­ëŸ‰ì„ í¬í•¨í•˜ëŠ” ë‚´ìš©ìœ¼ë¡œ ì œì‹œ
            [2] ì§„ë¡œì—­ëŸ‰ë¥¼ í¬í•¨í•˜ëŠ” ë‚´ìš©ìœ¼ë¡œ ì œì‹œ
            [3] ê³µë™ì²´ì—­ëŸ‰ë¥¼ í¬í•¨í•˜ëŠ” ë‚´ìš©ìœ¼ë¡œ ì œì‹œ
            
            **ì¤‘ìš”**: ì•„ë˜ ê¸°ì¡´ì— ì œì‹œëœ ì¤‘ê°„ ëª©í‘œë“¤ê³¼ëŠ” ì™„ì „íˆ ë‹¤ë¥¸ ìƒˆë¡œìš´ ì ‘ê·¼ë²•ì˜ ëª©í‘œë¥¼ ì œì‹œí•´ì£¼ì„¸ìš”:
            {existing_midgoals_text}
            """
            
            midgoals = call_gpt_list(
                prompt=regenerate_prompt,
                system_message="ë„ˆëŠ” ì§„ë¡œ íƒìƒ‰ì„ ë•ëŠ” ì°½ì˜ì ì¸ ì–´ì‹œìŠ¤í„´íŠ¸ì•¼. ê¸°ì¡´ê³¼ëŠ” ì™„ì „íˆ ë‹¤ë¥¸ ìƒˆë¡œìš´ ë°©ë²•ë¡ ì˜ ì¤‘ê°„ ëª©í‘œ 3ê°€ì§€ë¥¼ í•œêµ­ì–´ë¡œ ê°„ê²°í•˜ê²Œ ì œì‹œí•´ì¤˜. ê¸°ì¡´ ëª©í‘œì™€ ìœ ì‚¬í•˜ê±°ë‚˜ ì¤‘ë³µë˜ëŠ” ë‚´ìš©ì€ ì ˆëŒ€ í”¼í•´ì¤˜.",
                max_completion_tokens=3000,
                temperature=0.3,
                fallback=["ì¤‘ê°„ ëª©í‘œë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."],
                strip_chars='-â€¢[]1234567890. '
            )
            chatbot_message = "ì•„ë˜ì™€ ê°™ì´ ìƒˆë¡­ê²Œ ì¤‘ê°„ ëª©í‘œë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ë§ˆìŒì— ë“¤ì§€ ì•Šìœ¼ë©´ ë‹¤ì‹œ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            context.update({
                "step": 6, 
                "career": career, 
                "reasons": reasons, 
                "issues_selected": issues_selected, 
                "topic": topic, 
                "goal": goal, 
                "midgoals": midgoals, 
                "chatbot_message": chatbot_message,
                
            })
            return templates.TemplateResponse("career_flow_allinone.html", context)
        
        # "ë‹¤ìŒ" ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ 7ë‹¨ê³„ë¡œ ì´ë™
        chatbot_message = "ë“œë¦¼ë¡œì§ì´ ëª¨ë‘ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ì•„ë˜ëŠ” ë‹¹ì‹ ì˜ ì§„ë¡œ íƒìƒ‰ ê²°ê³¼ì…ë‹ˆë‹¤."
        # ìµœì¢… ìš”ì•½ ìƒì„±
        final_summary_text = call_gpt_list(
            prompt=career_final_summary_prompt.format(
                career=career, 
                reasons=reasons, 
                issue=issues_selected[0] if issues_selected else "", 
                topic=topic, 
                goal=goal, 
                midgoals=midgoals
            ),
            system_message="ë„ˆëŠ” ì§„ë¡œ íƒìƒ‰ì„ ë•ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ì•¼. ì‚¬ìš©ìì˜ ì§„ë¡œ íƒìƒ‰ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ ì²´ê³„ì ìœ¼ë¡œ ì •ë¦¬í•´ì¤˜. ìµœì¢…ëª©í‘œ, ì¤‘ê°„ëª©í‘œ, ì‹¤ì²œí™œë™ì—ë§Œ ì´ëª¨ì§€ë¥¼ ì‚¬ìš©í•˜ê³ , ì œí•œì¡°ê±´ì€ ê²°ê³¼ì— í‘œì‹œí•˜ì§€ ë§ê³  ë‚´ë¶€ì ìœ¼ë¡œë§Œ ì°¸ê³ í•´ì„œ ì‘ì„±í•´ì¤˜.",
            
            max_completion_tokens=None,  # ë¬´ì œí•œ í† í° ì‚¬ìš©
            fallback=["ìµœì¢… ìš”ì•½ì„ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."],
            strip_chars=''
        )
        final_summary = '\n'.join(final_summary_text) if final_summary_text else "ìµœì¢… ìš”ì•½ì„ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
        
        context.update({
            "step": 7, 
            "career": career, 
            "reasons": reasons, 
            "issues_selected": issues_selected, 
            "topic": topic, 
            "goal": goal, 
            "midgoals": midgoals,
            "final_summary": final_summary,
            "chatbot_message": chatbot_message,
            
        })
        return templates.TemplateResponse("career_flow_allinone.html", context)
        
    # 7ë‹¨ê³„: ìµœì¢… í†µí•© ìš”ì•½ ì¬ìƒì„±
    elif step == 7:
        form = await request.form()
        regenerate = form.get("regenerate")
        issues_selected = form.getlist("issues_selected")
        
        # ì¬ìƒì„± ìš”ì²­ ì‹œì—ë§Œ ì²˜ë¦¬
        if regenerate == "yes":
            # ê¸°ì¡´ ìµœì¢… ìš”ì•½ì„ í¼ì—ì„œ ë°›ì•„ì˜´
            current_summary = form.get("current_summary") or ""
            
            # ìƒˆë¡œìš´ í”„ë¡¬í”„íŠ¸ë¡œ ê¸°ì¡´ ìš”ì•½ê³¼ ë‹¤ë¥¸ ìš”ì•½ ìƒì„±
            regenerate_prompt = f"""
            7ë‹¨ê³„ - ìƒˆë¡œìš´ ìµœì¢… ì¢…í•© ê³„íš ìƒì„±.
            ì§€ê¸ˆê¹Œì§€ ì„ íƒí•œ ì§ì—…: '{career}', ì´ìœ : {reasons}, ì´ìŠˆ: '{issues_selected[0] if issues_selected else ""}', íƒêµ¬ ì£¼ì œ: '{topic}',
            ìµœì¢… ëª©í‘œ: '{goal}', ì¤‘ê°„ ëª©í‘œ: {midgoals}, ì„(ë¥¼) ë°”íƒ•ìœ¼ë¡œ ì•„ë˜ í˜•ì‹ìœ¼ë¡œ ëª¨ë“  ë‚´ìš©ì„ ëŒ€í•œë¯¼êµ­ ê³ ë“±í•™êµì—ì„œ ìˆ˜í–‰í•  ìˆ˜ ìˆëŠ” ìˆ˜ì¤€ì—ì„œ í†µí•©í•˜ì—¬ ì •ë¦¬í•´ ì£¼ì„¸ìš”.
            ìµœì¢…ëª©í‘œ, ì¤‘ê°„ëª©í‘œ, ì‹¤ì²œí™œë™ì—ë§Œ ì´ëª¨ì§€ë¥¼ ì‚¬ìš©í•´ì„œ ì‹œê°ì ìœ¼ë¡œ ë§¤ë ¥ì ì´ê³  ì½ê¸° ì‰½ê²Œ ë§Œë“¤ì–´ì£¼ì„¸ìš”.
            
            **ì¤‘ìš”**: ì´ì „ì— ì œì‹œëœ ì‹¤ì²œí™œë™ë“¤ê³¼ëŠ” ì™„ì „íˆ ë‹¤ë¥¸ ìƒˆë¡œìš´ ì ‘ê·¼ë²•ì˜ í™œë™ë“¤ì„ ì œì‹œí•´ì£¼ì„¸ìš”.
            ë‹¤ì–‘í•œ êµê³¼ëª©ê³¼ ë¹„êµê³¼ í™œë™ì„ í™œìš©í•˜ì—¬ ì°½ì˜ì ì´ê³  ë…ì°½ì ì¸ ì‹¤ì²œ ë°©ì•ˆì„ ì œì•ˆí•´ì£¼ì„¸ìš”.
            
    ì œí•œì¡°ê±´ì€ ê²°ê³¼ì— í‘œì‹œí•˜ì§€ ë§ê³  ë‚´ë¶€ì ìœ¼ë¡œë§Œ ì°¸ê³ í•˜ì„¸ìš”:
    ì•„ë˜ëŠ” ê±´ì¶•ê°€ë¥¼ í¬ë§í•˜ëŠ” ê³ ë“±í•™ìƒì˜ ì§„ë¡œ íƒìƒ‰ ê²°ê³¼ ì˜ˆì‹œì…ë‹ˆë‹¤.
    
    # ì˜ˆì‹œ:
        ğŸ¯ [ìµœì¢… ëª©í‘œ(ê¿ˆ)] ê¸°í›„ ìœ„ê¸° ëŒ€ì‘ì„ ìœ„í•œ ì¹œí™˜ê²½ ê±´ì¶• ì‹œìŠ¤í…œ ì„¤ê³„í•˜ì—¬ ì§€ì†ê°€ëŠ¥í•œ ë¯¸ë˜ ì£¼ê±° í˜•íƒœë¥¼ ì‹¤í˜„í•˜ëŠ” ê±´ì¶•ê°€

        ğŸ“š [ì¤‘ê°„ëª©í‘œ1] ì¹œí™˜ê²½ ê±´ì¶• ê¸°ìˆ  ì—­ëŸ‰
        ğŸ”¬ ì‹¤ì²œí™œë™1:
                    íƒêµ¬ë³´ê³ ì„œ: "ì œë¡œì—ë„ˆì§€ ê±´ì¶• ê¸°ìˆ ì˜ ì‹¤ì œ ì ìš© ì‚¬ë¡€ ë¶„ì„" ë“±
                    êµê³¼ í™œë™: ê³¼í•™ - 'ì—ë„ˆì§€ ì „í™˜' ë‹¨ì› [ì‹¬í™”]
                    ë¹„êµê³¼: ì—ë„ˆì§€ ì°½ì˜ ì„¤ê³„ ìº í”„ ì°¸ê°€ - [ë¬¸ì œ í•´ê²°ë ¥ ì„±ì¥ê³¼ ê´€ë ¨]
        ğŸ”¬ ì‹¤ì²œí™œë™2:
                    íƒêµ¬ë³´ê³ ì„œ:
                    êµê³¼ í™œë™: ê³¼í•™ - 'ìœ ì „ì í¸ì§‘ ê¸°ìˆ ' ë‹¨ì› [ì‹¬í™”]
                    ë¹„êµê³¼:
        ğŸ”¬ ì‹¤ì²œí™œë™3:
                    íƒêµ¬ë³´ê³ ì„œ:  
                    êµê³¼ í™œë™: ê³¼í•™ - ìœ ì „ìì™€~~
                    ë¹„êµê³¼:  
        
        ğŸ¨ [ì¤‘ê°„ëª©í‘œ2] ì„¤ê³„ ëŠ¥ë ¥ í–¥ìƒ
        ğŸ”¬ ì‹¤ì²œí™œë™1:
                    íƒêµ¬ë³´ê³ ì„œ: "ê±´ì¶• ì„¤ê³„ì˜ ê¸°ì´ˆì™€ ì‹¤ì œ" ë“±
                    êµê³¼ í™œë™: ê¸°íƒ€ - 'ê¸°ì´ˆ ì„¤ê³„ ì›ë¦¬'
                    ë¹„êµê³¼: ê±´ì¶• ì„¤ê³„ ì›Œí¬ìˆ ì°¸ê°€ - [ì°½ì˜ì  ë¬¸ì œ í•´ê²°ë ¥ ì„±ì¥ê³¼ ê´€ë ¨]
        ğŸ”¬ ì‹¤ì²œí™œë™2:
                    íƒêµ¬ë³´ê³ ì„œ: "ê±´ì¶• ì„¤ê³„ì˜ ê¸°ì´ˆì™€ ì‹¤ì œ" ë“±
                    êµê³¼ í™œë™: ê¸°íƒ€ - 'ê³ ê¸‰ ì„¤ê³„ ê¸°ë²•'
                    ë¹„êµê³¼: ê±´ì¶• ì„¤ê³„ ê²½ì§„ëŒ€íšŒ ì°¸ê°€ - [ì°½ì˜ì  ë¬¸ì œ í•´ê²°ë ¥ ì„±ì¥ê³¼ ê´€ë ¨]
        ğŸ”¬ ì‹¤ì²œí™œë™3:
                    íƒêµ¬ë³´ê³ ì„œ: "ê±´ì¶• ì„¤ê³„ì˜ ê¸°ì´ˆì™€ ì‹¤ì œ" ë“±
                    êµê³¼ í™œë™: ê¸°íƒ€ - 'ê±´ì¶• ì„¤ê³„ í”„ë¡œì íŠ¸'
                    ë¹„êµê³¼: ê±´ì¶• ì„¤ê³„ í”„ë¡œì íŠ¸ ë°œí‘œíšŒ ì°¸ê°€ - [ì°½ì˜ì  ë¬¸ì œ í•´ê²°ë ¥ ì„±ì¥ê³¼ ê´€ë ¨]
        
        ğŸ¤ [ì¤‘ê°„ëª©í‘œ3] ê³µë™ì²´ì  ì‹¤ì²œì˜ì‹ í•¨ì–‘
        ğŸ”¬ ì‹¤ì²œí™œë™1:
        
        ì œí•œ ì¡°ê±´ (ê²°ê³¼ì— í‘œì‹œí•˜ì§€ ë§ê³  ë‚´ë¶€ì ìœ¼ë¡œë§Œ ì°¸ê³ ):
        0. í•™ë…„ë³„ êµê³¼ í™œë™ì˜ ê²½ìš° ì•„ë˜ í‘œì‹œí•œ'2022 êµìœ¡ê°œí¸ì¤‘ ê³ ë“±í•™êµ êµìœ¡ê³¼ì •' ë°˜ì˜í•˜ì—¬ í™œë™ ì œì‹œ
            ì œí•œ ì¡°ê±´ (ê²°ê³¼ì— í‘œì‹œí•˜ì§€ ë§ê³  ë‚´ë¶€ì ìœ¼ë¡œë§Œ ì°¸ê³ ):
        1. êµê³¼ í™œë™ì€ ë°˜ë“œì‹œ 2022 ê°œì • êµìœ¡ê³¼ì •ì˜ ì •í™•í•œ êµê³¼ëª©ëª…ë§Œ ì‚¬ìš©:
            ì•„ë˜ í˜•ì‹ì€ **ì˜ì—­**:ê³¼ëª©ëª….. ìœ¼ë¡œ í‘œì‹œ
            **êµ­ì–´**: ê³µí†µêµ­ì–´, í™”ë²•ê³¼ ì–¸ì–´, ë…ì„œì™€ ì‘ë¬¸, ë¬¸í•™, ì£¼ì œ íƒêµ¬ ë…ì„œ, ë¬¸í•™ê³¼ ì˜ìƒ, ì§ë¬´ ì˜ì‚¬ì†Œí†µ, ë…ì„œ í† ë¡ ê³¼ ê¸€ì“°ê¸°, ë§¤ì²´ ì˜ì‚¬ì†Œí†µ, ì–¸ì–´ìƒí™œ íƒêµ¬
            **ìˆ˜í•™**: ê³µí†µìˆ˜í•™, ëŒ€ìˆ˜, ë¯¸ì ë¶„, í™•ë¥ ê³¼ í†µê³„, ê¸°í•˜, ê²½ì œ ìˆ˜í•™, ì¸ê³µì§€ëŠ¥ ìˆ˜í•™, ì§ë¬´ìˆ˜í•™, ìˆ˜í•™ê³¼ ë¬¸í™”, ì‹¤ìš©í†µê³„, ìˆ˜í•™ê³¼ì œ íƒêµ¬
            **ì˜ì–´**: ê³µí†µì˜ì–´, ì˜ì–´ ë…í•´ì™€ ì‘ë¬¸, ì˜ë¯¸ ë¬¸í•™ ì½ê¸°, ì˜ì–´ ë°œí‘œì™€ í† ë¡ , ì‹¬í™” ì˜ì–´, ì§ë¬´ ì˜ì–´, ì‹¤ìƒí™œ ì˜ì–´íšŒí™”, ë¯¸ë””ì–´ ì˜ì–´, ì„¸ê³„ ë¬¸í™”ì™€ ì˜ì–´
            **ì‚¬íšŒ**: í•œêµ­ì‚¬, í†µí•©ì‚¬íšŒ, ì„¸ê³„ì‹œë¯¼ê³¼ ì§€ë¦¬, ì„¸ê³„ì‚¬, ì‚¬íšŒì™€ ë¬¸í™”, í˜„ëŒ€ì‚¬íšŒì™€ ìœ¤ë¦¬, í•œêµ­ì§€ë¦¬ íƒêµ¬, ë„ì‹œì˜ ë¯¸ë˜ íƒêµ¬, ë™ì•„ì‹œì•„ ì—­ì‚¬ ê¸°í–‰, ì •ì¹˜, ë²•ê³¼ ì‚¬íšŒ, ê²½ì œ, ì‚¬íšŒ ë¬¸ì œ íƒêµ¬, ìœ¤ë¦¬ì™€ ì‚¬ìƒ, ì¸ë¬¸í•™ê³¼ ìœ¤ë¦¬, êµ­ì œ ê´€ê³„ì˜ ì´í•´, ì—¬í–‰ì§€ë¦¬, ì—­ì‚¬ë¥¼ íƒêµ¬í•˜ëŠ” í˜„ëŒ€ ì„¸ê³„, ê¸ˆìœµê³¼ ê²½ì œìƒí™œ, ìœ¤ë¦¬ë¬¸ì œ íƒêµ¬, ê¸°í›„ë³€í™”ì™€ ì§€ì†ê°€ëŠ¥í•œ ì„¸ê³„
            **ê³¼í•™**: í†µí•©ê³¼í•™, ê³¼í•™íƒêµ¬ì‹¤í—˜, ë¬¼ë¦¬í•™, í™”í•™, ìƒëª…ê³¼í•™, ì§€êµ¬ê³¼í•™, ì—­í•™ê³¼ ì—ë„ˆì§€, ì „ìê¸°ì™€ ì–‘ì, ë¬¼ì§ˆê³¼ ì—ë„ˆì§€, í™”í•™ë°˜ì‘ì˜ ì„¸ê³„, ì„¸í¬ì™€ ë¬¼ì§ˆëŒ€ì‚¬, ìƒë¬¼ì˜ ìœ ì „, ì§€êµ¬ ì‹œìŠ¤í…œê³¼í•™, í–‰ì„±ìš°ì£¼ê³¼í•™, ê³¼í•™ì˜ ì—­ì‚¬ì™€ ë¬¸í™”, ê¸°í›„ë³€í™”ì™€ í™˜ê²½ìƒíƒœ, ìœµí•©ê³¼í•™ íƒêµ¬
            **ê¸°íƒ€**: ê¸°ìˆ ê°€ì •, ì •ë³´, ë¡œë´‡ê³¼ ê³µí•™ì„¸ê³„, ìƒí™œê³¼í•™ íƒêµ¬, ì¸ê³µì§€ëŠ¥ ê¸°ì´ˆ, ë°ì´í„° ê³¼í•™, ì°½ì˜ ê³µí•™ ì„¤ê³„, ì§€ì‹ ì¬ì‚° ì¼ë°˜, ìƒì• ì„¤ê³„ì™€ ìë¦½, ì²´ìœ¡, ì˜ˆìˆ 
        2. í•™êµì™¸ì— ëŒ€íšŒë‚˜ ê³µëª¨ì „ì€ ì–¸ê¸‰í•˜ì§€ ì•Šê¸°. í•™êµì—ì„œ ì´ë£¨ì–´ì§ˆ ìˆ˜ ìˆëŠ” í™œë™ìœ¼ë¡œë§Œ ì‹¤ì²œí™œë™ ì œì‹œí•˜ê¸°
        3. ìì†Œì„œ ë“±ì€ ì–¸ê¸‰í•˜ì§€ ì•Šê¸°
        4. ê³ ë“±í•™ìƒ ìˆ˜ì¤€ì—ì„œ ì´í•´ í•  ìˆ˜ ìˆëŠ” íƒêµ¬í™œë™ ì£¼ì œ ì œì‹œ
            "ê° í•­ëª©ì€ ì‹¤ì œ ì…ë ¥ê°’ì— ë§ê²Œ êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”."
            """
            
            # ìµœì¢… ìš”ì•½ ì¬ìƒì„±
            final_summary_text = call_gpt_list(
                prompt=regenerate_prompt,
                system_message="ë„ˆëŠ” ì§„ë¡œ íƒìƒ‰ì„ ë•ëŠ” ì°½ì˜ì ì¸ ì–´ì‹œìŠ¤í„´íŠ¸ì•¼. ê¸°ì¡´ê³¼ëŠ” ì™„ì „íˆ ë‹¤ë¥¸ ìƒˆë¡œìš´ ê´€ì ì˜ ì‹¤ì²œí™œë™ë“¤ì„ í¬í•¨í•˜ì—¬ ì‚¬ìš©ìì˜ ì§„ë¡œ íƒìƒ‰ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ ì²´ê³„ì ìœ¼ë¡œ ì •ë¦¬í•´ì¤˜. ìµœì¢…ëª©í‘œ, ì¤‘ê°„ëª©í‘œ, ì‹¤ì²œí™œë™ì—ë§Œ ì´ëª¨ì§€ë¥¼ ì‚¬ìš©í•˜ê³ , ì œí•œì¡°ê±´ì€ ê²°ê³¼ì— í‘œì‹œí•˜ì§€ ë§ê³  ë‚´ë¶€ì ìœ¼ë¡œë§Œ ì°¸ê³ í•´ì„œ ì‘ì„±í•´ì¤˜.",
                max_completion_tokens=None,  # ë¬´ì œí•œ í† í° ì‚¬ìš©
                temperature=0.3,
                fallback=["ìµœì¢… ìš”ì•½ì„ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."],
                strip_chars=''
            )
            final_summary = '\n'.join(final_summary_text) if final_summary_text else "ìµœì¢… ìš”ì•½ì„ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
            
            chatbot_message = "ì•„ë˜ì™€ ê°™ì´ ìƒˆë¡­ê²Œ ìµœì¢… ìš”ì•½ì„ ì œì•ˆí•©ë‹ˆë‹¤."
            context.update({
                "step": 7, 
                "career": career, 
                "reasons": reasons, 
                "issues_selected": issues_selected, 
                "topic": topic, 
                "goal": goal, 
                "midgoals": midgoals,
                "final_summary": final_summary,
                "chatbot_message": chatbot_message,
                
            })
            return templates.TemplateResponse("career_flow_allinone.html", context)


def translate_career_to_english(career_korean):
    """í•œê¸€ ì§ì—…ëª…ì„ ì˜ì–´ë¡œ ë²ˆì—­"""
    try:
        # í•œê¸€ì´ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
        has_korean = any('\uac00' <= char <= '\ud7af' for char in career_korean)
        
        if not has_korean:
            # í•œê¸€ì´ ì—†ìœ¼ë©´ ì˜ì–´ë¡œ ê°„ì£¼í•˜ê³  ì •ë¦¬ë§Œ
            english_career = ''.join(c for c in career_korean if c.isalnum() or c.isspace())
            result = english_career.lower().replace(' ', '_')
            return result
        
        # í•œê¸€ì´ ìˆëŠ” ê²½ìš° OpenAIë¡œ ë²ˆì—­
        chat_completion = client.chat.completions.create(
            model=DEFAULT_GPT_MODEL,
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ í•œêµ­ì–´ ì§ì—…ëª…ì„ ì˜ì–´ë¡œ ë²ˆì—­í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì§ì—…ëª…ë§Œ ê°„ë‹¨í•˜ê²Œ ì˜ì–´ë¡œ ë²ˆì—­í•´ì£¼ì„¸ìš”. ë¶€ê°€ ì„¤ëª…ì€ í•˜ì§€ ë§ê³  ì§ì—…ëª…ë§Œ ë‹µë³€í•˜ì„¸ìš”."},
                {"role": "user", "content": f"ë‹¤ìŒ í•œêµ­ì–´ ì§ì—…ëª…ì„ ì˜ì–´ë¡œ ë²ˆì—­í•´ì£¼ì„¸ìš”: {career_korean}"},
            ],
            max_completion_tokens=200
        )
        
        english_career = chat_completion.choices[0].message.content
        if not english_career or not english_career.strip():
            english_career = "unknown_job"
        else:
            english_career = english_career.strip()
        
        # íŠ¹ìˆ˜ë¬¸ì ì œê±°í•˜ê³  ì†Œë¬¸ìë¡œ ë³€í™˜, ê³µë°±ì„ ì–¸ë”ìŠ¤ì½”ì–´ë¡œ
        english_career = ''.join(c for c in english_career if c.isalnum() or c.isspace())
        english_career = english_career.lower().replace(' ', '_')
        
        # ë¹ˆ ë¬¸ìì—´ ì²´í¬
        if not english_career or english_career == '_':
            english_career = "unknown_job"
        
        return english_career
        
    except Exception as e:
        # ë²ˆì—­ ì‹¤íŒ¨ ì‹œ í•œê¸€ì„ ì•ˆì „í•œ í˜•íƒœë¡œ ë³€í™˜
        import re
        safe_career = re.sub(r'[^\w\sê°€-í£]', '', career_korean)
        safe_career = re.sub(r'\s+', '_', safe_career.strip())
        result = f"korean_job_{safe_career}" if safe_career else "unknown_job"
        return result


@app.post("/career/download-pdf")
async def download_pdf(
    career: str = Form(...),
    reasons: List[str] = Form(...),
    issues_selected: List[str] = Form(...),
    topic: str = Form(...),
    goal: str = Form(...),
    midgoals: List[str] = Form(...),
    final_summary: str = Form(...)
):
    """7ë‹¨ê³„ ê²°ê³¼ë¥¼ PDFë¡œ ë‹¤ìš´ë¡œë“œ"""
    try:
        # ì§„ë¡œ ë°ì´í„° êµ¬ì„±
        career_data = {
            'career': career,
            'reasons': reasons,
            'issues_selected': issues_selected,
            'topic': topic,
            'goal': goal,
            'midgoals': midgoals,
            'final_summary': final_summary
        }
        
        # PDF ìƒì„±
        pdf_file = create_pdf_report(career_data)
        
        if pdf_file:
            # ë‹¤ìš´ë¡œë“œ íŒŒì¼ëª… ìƒì„± (í•œê¸€ ì§ì—…ëª…ì„ ì˜ì–´ë¡œ ë²ˆì—­)
            import re
            import urllib.parse
            
            # í•œê¸€ ì§ì—…ëª…ì„ ì˜ì–´ë¡œ ë²ˆì—­
            english_career = translate_career_to_english(career)
            
            # íŒŒì¼ëª…ì„ ì˜ë¬¸ìœ¼ë¡œ ìƒì„± (ë‚ ì§œë§Œ í¬í•¨, ì‹œê°„ ì œì™¸)
            timestamp = datetime.now().strftime('%Y%m%d')
            
            # ë²ˆì—­ëœ ì§ì—…ëª…ì´ ìˆìœ¼ë©´ ì¶”ê°€, ì—†ìœ¼ë©´ ê¸°ë³¸ íŒŒì¼ëª…
            if english_career and english_career.strip():
                filename = f"dreamlogic_career_report_{timestamp}_{english_career}.pdf"
            else:
                filename = f"dreamlogic_career_report_{timestamp}_unknown_job.pdf"
            
            # í•œê¸€ íŒŒì¼ëª…ë„ ìƒì„± (UTF-8 ì¸ì½”ë”©)
            safe_career = re.sub(r'[^\w\sê°€-í£]', '', career)
            safe_career = re.sub(r'\s+', '_', safe_career.strip())
            korean_filename = f"ë“œë¦¼ë¡œì§_ì§„ë¡œíƒìƒ‰ê²°ê³¼_{safe_career}_{timestamp}.pdf"
            encoded_korean_filename = urllib.parse.quote(korean_filename)
            
            # Content-Disposition í—¤ë” ì„¤ì • (ì˜ì–´ íŒŒì¼ëª… + í•œê¸€ íŒŒì¼ëª… ì˜µì…˜)
            return FileResponse(
                pdf_file,
                media_type='application/pdf',
                filename=filename,
                headers={
                    "Content-Disposition": f'attachment; filename="{filename}"; filename*=UTF-8\'\'{encoded_korean_filename}'
                }
            )
        else:
            return HTMLResponse("PDF ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.", status_code=500)
            
    except Exception as e:
        print(f"PDF ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜: {e}")
        return HTMLResponse(f"PDF ë‹¤ìš´ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}", status_code=500)

def call_gpt_list(prompt, system_message, max_completion_tokens=None, temperature=0.3, fallback=None, strip_chars='-â€¢[]1234567890. '):
    """
    GPT ëª¨ë¸ë¡œ ë¦¬ìŠ¤íŠ¸ í˜•íƒœì˜ ì‘ë‹µì„ ë°›ì•„ íŒŒì‹±í•˜ëŠ” í—¬í¼ í•¨ìˆ˜
    ì›¹ ë°°í¬ í™˜ê²½ì—ì„œì˜ ì•ˆì •ì„±ì„ ìœ„í•´ ì¬ì‹œë„ ë¡œì§ê³¼ í–¥ìƒëœ ì—ëŸ¬ ì²˜ë¦¬ ì¶”ê°€
    max_completion_tokens=Noneìœ¼ë¡œ ì„¤ì •í•˜ë©´ ë¬´ì œí•œ í† í° ì‚¬ìš©
    """
    import time
    
    for attempt in range(3):  # ìµœëŒ€ 3ë²ˆ ì¬ì‹œë„
        try:
            # GPT-5 ëª¨ë¸ì¼ ë•Œ í† í° ìˆ˜ë¥¼ 50%ë¡œ ì¤„ì„
            adjusted_tokens = max_completion_tokens
            if max_completion_tokens is not None and DEFAULT_GPT_MODEL == "gpt-5":
                adjusted_tokens = int(max_completion_tokens * 0.5)
            
            # API í˜¸ì¶œ ë§¤ê°œë³€ìˆ˜ ì¤€ë¹„
            api_params = {
                "model": DEFAULT_GPT_MODEL,
                "messages": [
                    {"role": "system", "content": system_message},
                    {"role": "user", "content": prompt},
                ],
                "temperature": temperature,
                "timeout": 30  # 30ì´ˆ íƒ€ì„ì•„ì›ƒ ì„¤ì •
            }
            
            # max_completion_tokensê°€ Noneì´ ì•„ë‹Œ ê²½ìš°ì—ë§Œ ì¶”ê°€
            if adjusted_tokens is not None:
                api_params["max_completion_tokens"] = adjusted_tokens
            
            chat_completion = client.chat.completions.create(**api_params)
            
            content = chat_completion.choices[0].message.content or ""
            lines = content.split('\n')
            
            # ì„¤ëª… ë¬¸ì¥ ì œê±°: ì½œë¡ (:)ì´ í¬í•¨ëœ ì²« ë²ˆì§¸ ì¤„ë“¤ì€ ì œì™¸
            items = []
            for line in lines:
                line = line.strip()
                if not line:  # ë¹ˆ ì¤„ ê±´ë„ˆë›°ê¸°
                    continue
                # ì„¤ëª… ë¬¸ì¥ íŒ¨í„´ ì œê±° (ì½œë¡ ì´ í¬í•¨ë˜ê³  "ê°€ì§€", "ì…ë‹ˆë‹¤", "ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤" ë“±ì´ í¬í•¨ëœ ê²½ìš°)
                if ':' in line and any(word in line for word in ['ê°€ì§€', 'ì…ë‹ˆë‹¤', 'ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤', 'ì œì‹œ', 'ê´€ë ¨ëœ']):
                    continue
                # strip_charsë¡œ ë¶ˆí•„ìš”í•œ ë¬¸ì ì œê±°
                cleaned_line = line.strip(strip_chars).strip()
                if cleaned_line:  # ì •ë¦¬ëœ í›„ì—ë„ ë‚´ìš©ì´ ìˆìœ¼ë©´ ì¶”ê°€
                    items.append(cleaned_line)
            
            if not items and fallback:
                items = fallback
            return items
            
        except Exception as e:
            print(f"GPT API í˜¸ì¶œ ì‹œë„ {attempt + 1}/3 ì‹¤íŒ¨: {str(e)}")
            if attempt < 2:  # ë§ˆì§€ë§‰ ì‹œë„ê°€ ì•„ë‹ˆë©´ ì ì‹œ ëŒ€ê¸°
                time.sleep(2 ** attempt)  # ì§€ìˆ˜ ë°±ì˜¤í”„: 2ì´ˆ, 4ì´ˆ
            else:
                # ëª¨ë“  ì‹œë„ ì‹¤íŒ¨ ì‹œ í´ë°± ë°˜í™˜
                error_message = f"API í˜¸ì¶œ ì‹¤íŒ¨ (ëª¨ë¸: {DEFAULT_GPT_MODEL}): {str(e)}"
                print(error_message)
                return fallback if fallback else [f"ì´ìŠˆë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."]


def setup_korean_font():
    """í•œê¸€ í°íŠ¸ ì„¤ì • (ì›¹ í˜¸í™˜ì„± ìš°ì„ )"""
    font_name = 'Helvetica'  # ê¸°ë³¸ê°’
    
    # ì›¹ í˜¸í™˜ í•œê¸€ í°íŠ¸ ê²½ë¡œ (ìš°ì„ ìˆœìœ„)
    font_paths = [
        # 1ìˆœìœ„: ë„¤ì´ë²„ ë‚˜ëˆ”ê³ ë”• (ì›¹ ì„œë¹„ìŠ¤ í˜¸í™˜ì„± ìµœìš°ì„ )
        os.path.join(os.path.dirname(__file__), "fonts", "NanumGothic.ttf"),
        # 2ìˆœìœ„: macOS ì‹œìŠ¤í…œ í°íŠ¸ (ê°œë°œ í™˜ê²½ìš©)
        '/System/Library/Fonts/AppleSDGothicNeo.ttc',
        # 3ìˆœìœ„: Linux í™˜ê²½ì˜ ë‚˜ëˆ”ê³ ë”•
        '/usr/share/fonts/truetype/nanum/NanumGothic.ttf',  # Ubuntu/Debian
        '/usr/share/fonts/nanum-gothic/NanumGothic.ttf',    # CentOS/RHEL
        # 4ìˆœìœ„: Windows í™˜ê²½
        'C:/Windows/Fonts/malgun.ttf',  # ë§‘ì€ ê³ ë”•
    ]
    
    for i, font_path in enumerate(font_paths):
        if os.path.exists(font_path):
            try:
                font_reg_name = f'NanumGothic{i}'
                
                if font_path.endswith('.ttc'):
                    # TTC íŒŒì¼ì˜ ê²½ìš° ì„œë¸Œí°íŠ¸ ì§€ì •
                    pdfmetrics.registerFont(TTFont(font_reg_name, font_path, subfontIndex=0))
                else:
                    # TTF íŒŒì¼
                    pdfmetrics.registerFont(TTFont(font_reg_name, font_path))
                
                font_name = font_reg_name
                print(f"âœ… í°íŠ¸ ë“±ë¡ ì„±ê³µ: {font_path} â†’ {font_name}")
                break
            except Exception as e:
                print(f"âŒ í°íŠ¸ ë“±ë¡ ì‹¤íŒ¨ {font_path}: {e}")
                continue
    
    print(f"ğŸ”¤ ìµœì¢… ì‚¬ìš© í°íŠ¸: {font_name}")
    return font_name


def clean_text_for_pdf(text):
    """PDF í˜¸í™˜ì„±ì„ ìœ„í•œ í…ìŠ¤íŠ¸ ì •ë¦¬"""
    if not text:
        return ""
    
    text = str(text)
    
    # ì´ëª¨ì§€ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
    emoji_map = {
        'ğŸ¯': 'â¦¿',  'ğŸ“š': 'ğŸ“–',  'ğŸ¨': 'ğŸ–¼',  'ğŸ¤': 'ğŸ‘¥',  'ğŸ”¬': 'â€¢',
        'âœ¨': 'â˜…',  'ğŸ ': 'ğŸ˜',  'ğŸ’¼': 'ğŸ‘”',  'ğŸ“': 'âœ',  'ğŸŒŸ': 'â­',
        'ğŸ“…': '[ë‚ ì§œ]', 'ğŸ“': '[êµìœ¡]', 'ğŸ’¡': '[ì•„ì´ë””ì–´]', 'ğŸš€': '[ì‹œì‘]',
        'â¤ï¸': 'â™¥', 'ğŸ‘': '[ì¢‹ìŒ]', 'ğŸ”¥': '[ì¸ê¸°]', 'ğŸ’ª': '[í˜]'
    }
    
    for emoji, replacement in emoji_map.items():
        text = text.replace(emoji, replacement)
    
    # HTML íŠ¹ìˆ˜ë¬¸ì ì²˜ë¦¬
    text = text.replace('&', '&amp;')
    text = text.replace('<', '&lt;')
    text = text.replace('>', '&gt;')
    
    return text


def create_pdf_report(career_data):
    """ì§„ë¡œ íƒìƒ‰ PDF ë³´ê³ ì„œ ìƒì„±"""
    # í•œê¸€ í°íŠ¸ ì„¤ì •
    font_name = setup_korean_font()
    
    # ì„ì‹œ íŒŒì¼ ìƒì„±
    temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.pdf')
    temp_filename = temp_file.name
    temp_file.close()
    
    # PDF ë¬¸ì„œ ìƒì„±
    doc = SimpleDocTemplate(
        temp_filename,
        pagesize=A4,
        leftMargin=inch*0.7,
        rightMargin=inch*0.7,
        topMargin=inch*0.8,
        bottomMargin=inch*0.8
    )
    
    # ìŠ¤íƒ€ì¼ ì„¤ì •
    styles = getSampleStyleSheet()
    
    title_style = ParagraphStyle(
        'KoreanTitle',
        parent=styles['Title'],
        fontName=font_name,
        fontSize=22,
        spaceAfter=30,
        alignment=1  # ì¤‘ì•™ ì •ë ¬
    )
    
    heading_style = ParagraphStyle(
        'KoreanHeading',
        parent=styles['Heading2'],
        fontName=font_name,
        fontSize=15,
        spaceAfter=12,
        spaceBefore=18
    )
    
    normal_style = ParagraphStyle(
        'KoreanNormal',
        parent=styles['Normal'],
        fontName=font_name,
        fontSize=11,
        spaceAfter=10,
        leading=16
    )
    
    bullet_style = ParagraphStyle(
        'KoreanBullet',
        parent=styles['Normal'],
        fontName=font_name,
        fontSize=11,
        spaceAfter=8,
        leading=16,
        leftIndent=20
    )
    
    story = []
    
    # ì œëª©
    story.append(Paragraph("â¦¿ ë“œë¦¼ë¡œì§ ì§„ë¡œ íƒìƒ‰ ê²°ê³¼", title_style))
    story.append(Spacer(1, 20))
    
    # ìƒì„± ë‚ ì§œ
    current_date = datetime.now().strftime("%Yë…„ %mì›” %dì¼")
    story.append(Paragraph(f"ìƒì„±ì¼: {current_date}", normal_style))
    story.append(Spacer(1, 25))
    """
    # ì§„ë¡œ íƒìƒ‰ ì„¹ì…˜ë“¤
    sections = [
        ("1ï¸âƒ£ ì„ íƒí•œ ì§ì—…", career_data.get('career', 'ì •ë³´ ì—†ìŒ')),
        ("2ï¸âƒ£ ì§ì—… ì„ íƒ ì´ìœ ", career_data.get('reasons', ['ì •ë³´ ì—†ìŒ'])),
        ("3ï¸âƒ£ ê´€ì‹¬ ìˆëŠ” ì´ìŠˆ", career_data.get('issues_selected', ['ì •ë³´ ì—†ìŒ'])),
        ("4ï¸âƒ£ íƒêµ¬ ì£¼ì œ", career_data.get('topic', 'ì •ë³´ ì—†ìŒ')),
        ("5ï¸âƒ£ ì§„ë¡œ ëª©í‘œ", career_data.get('goal', 'ì •ë³´ ì—†ìŒ')),
        ("6ï¸âƒ£ ì¤‘ê°„ ëª©í‘œ", career_data.get('midgoals', ['ì •ë³´ ì—†ìŒ'])),
    ]
    
    for section_title, section_content in sections:
        # ì„¹ì…˜ ì œëª©
        clean_title = clean_text_for_pdf(section_title)
        story.append(Paragraph(clean_title, heading_style))
        
        # ì„¹ì…˜ ë‚´ìš©
        if isinstance(section_content, list):
            for i, item in enumerate(section_content, 1):
                clean_item = clean_text_for_pdf(item)
                if len(section_content) > 1:
                    story.append(Paragraph(f"{i}. {clean_item}", bullet_style))
                else:
                    story.append(Paragraph(f"â€¢ {clean_item}", bullet_style))
        else:
            clean_content = clean_text_for_pdf(section_content)
            story.append(Paragraph(f"â€¢ {clean_content}", bullet_style))
        
        story.append(Spacer(1, 15))
    """
    # ìµœì¢… ìš”ì•½
    final_summary = career_data.get('final_summary', '')
    if final_summary:
        story.append(Paragraph("ë“œë¦¼ë¡œì§", heading_style))
        
        # ì¤„ë°”ê¿ˆìœ¼ë¡œ ë¶„ë¦¬í•˜ì—¬ ì²˜ë¦¬
        summary_lines = str(final_summary).split('\n')
        for line in summary_lines:
            line = line.strip()
            if line:
                clean_line = clean_text_for_pdf(line)
                story.append(Paragraph(clean_line, normal_style))
    
    # PDF ìƒì„±
    try:
        doc.build(story)
        print(f"âœ… PDF ìƒì„± ì™„ë£Œ: {temp_filename}")
        return temp_filename
    except Exception as e:
        print(f"âŒ PDF ìƒì„± ì˜¤ë¥˜: {e}")
        return None

